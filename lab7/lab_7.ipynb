{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "2BSfnq0vZuTi",
    "tags": []
   },
   "source": [
    "# Systemy rekomendacyjne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "KBfWIhWbZuTj",
    "tags": []
   },
   "source": [
    "## Wstęp\n",
    "\n",
    "Celem laboratorium jest poznanie podstaw systemów rekomendacyjnych. Zapoznasz się na nim z następującymi tematami:\n",
    "* budową systemów rekomendacyjnych typu _collaborative filtering_ (CF), w szczególności z:\n",
    "  * macierzą interakcji _użytkownik-przedmiot_ (user-item matrix),\n",
    "  * pojęciem _biasu_ użytkownika i przedmiotu,\n",
    "  * analizą zbiorów danych do CF,\n",
    "  * metrykami jakości dla systemów rekomendacyjnych.\n",
    "* algorytmami globalnej rekomendacji:\n",
    "  * metodami podstawowymi (baselines),\n",
    "  * metodami bayesowskimi (Bayesian average).\n",
    "* algorytmami personalizowanej rekomendacji typu CF, w szczególności z:\n",
    "  * algorytmem najbliższych sąsiadów (neighborhood-based) typu user-based oraz item-based,\n",
    "  * rozkładem macierzowym (matrix factorization) typu MF oraz FunkSVD.\n",
    "\n",
    "Jak zwykle, możesz albo korzystać z Google Colab, albo z własnego komputera. W obu przypadkach trzeba doinstalować trochę bibliotek.\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/apohllo/sztuczna-inteligencja/blob/master/lab7/lab_7.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cf84O5-ZuTj"
   },
   "source": [
    "## Krótki wstęp teoretyczny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwERXb9RZuTk"
   },
   "source": [
    "**Systemy rekomendacyjne (recommender systems)** to dowolne metody mające rekomendować użytkownikom (_users_) pewne przedmioty (_items_). Korzysta z nich praktycznie każda większa firma: **Netflix** (filmy - \"Top picks for you\"), **Spotify** (muzyka, \"Recommended for playlist\"), **Amazon** (sklep - \"frequently bought together\") etc. Mają niesamowicie praktyczne zastosowanie i są jednym z najwcześniej oraz najczęściej wdrażanych metod uczenia maszynowego.\n",
    "\n",
    "Jest to bardzo szeroka dziedzina o bardzo różnorodnych podejściach. W szczególności można wyróżnić grupy:\n",
    "1. **Collaborative filtering (CF)** - oparte o historię interakcji użytkowników z przedmiotami, czyli zwykle o historię ocen. Stąd pochodzą np. rekomendacje \"użytkownicy podobni do ciebie oglądali także X\", gdzie podobieństwo mierzy się na podstawie tego, jak bardzo podobne mieliśmy w przeszłości oceny do innych użytkowników. Co ważne, takie podejście nie wymaga żadnej inżynierii cech, a jedynie zapamiętania historii ocen / transakcji / interakcji!\n",
    "2. **Content-based (CB)** - dużo bardziej podobne do klasycznego ML, tworzymy wektory cech dla przedmiotów oraz użytkowników i wykorzystujemy je w klasyfikacji (np. rekomendować lub nie) lub regresji (np. liczba gwiazdek).\n",
    "3. **Algorytmy hybrydowe** - łączące podejścia CF i CB podczas nauki. Są zazwyczaj bardziej złożone i wymagają odpowiednio dużych zbiorów danych.\n",
    "\n",
    "Dodatkowo możemy podzielić problemy rekomendacji na dwa rodzaje, w zależności od tego, czym są nasze **oceny (ratings)**:\n",
    "1. **Explicit feedback** - kiedy użytkownicy jawnie podają oceny, np. ocena hotelu w skali 1-10, liczba gwiazdek dla przedmiotu. Wymaga to większej proaktywności użytkowników, więc potencjalnie możemy mieć mniej danych, ale są często bardziej precyzyjne. Są też typowo prostsze teoretycznie (matematycznie), bo mają znany z góry, ograniczony zakres możliwych wartości.\n",
    "2. **Implicit feedback** - kiedy jakość przedmiotu wyznaczają akcje użytkowników, np. liczba kliknięć, liczba udostępnień. Takie informacje można gromadzić automatycznie i bardzo łatwo, ale mogą być mało precyzyjne (np. przypadkowe kliknięcia, boty). Algorytmy dla takich problemów są też cięższe do zaprojektowania, bo mamy tylko wartości nieujemne i typowo nieograniczone z góry.\n",
    "\n",
    "Same rekomendacje mogą być dwojakiego rodzaju:\n",
    "1. **Globalne (global)** - biorą pod uwagę ogólne cechy przedmiotu i są oceniane dla całej społeczności, nie pod konkretnych użytkowników. Korzystają z nich typowo strony z wiadomościami, żeby ułożyć kolejność postów na stronie, np. HackerNews, Reddit. Przydają się też, gdy nie mamy dość informacji o użytkowniku, aby dokonać personalizacji.\n",
    "2. **Personalizowane (personalized)** - zasadnicze zastosowanie systemów rekomendacyjnych, w którym \"profilujemy\" użytkownika lub przedmiot tak, aby nauczyć sie relacji między nimi i sugerować to, co konkretną osobę może interesować.\n",
    "\n",
    "Na tym laboratorium skupimy się na systemach typu collaborative filtering, bo są:\n",
    "1. Ciekawsze i bardziej unikatowe na tle tych algorytmów, które już poznaliśmy.\n",
    "2. Często o wiele łatwiejsze w praktycznej implementacji, gdyż nie wymagają feature engineeringu.\n",
    "3. Bardzo szybkie i skalowalne.\n",
    "4. Zazwyczaj lepsze pod względem wyników od systemów content-based.\n",
    "\n",
    "Skupimy się na systemach typu _explicit ranking_, bo są nieco prostsze i popularniejsze. Poznamy za to i systemy globalne, i personalizowane.\n",
    "\n",
    "Czemu więc korzystać z innego podejścia niż CF? O tym przekonasz się w późniejszej części labu :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg-xFe4NZuTk"
   },
   "source": [
    "## Biblioteki do systemów rekomendacyjnych\n",
    "\n",
    "Do systemów rekomendacyjnych nie istnieje jedna standardowa, powszechnie przyjęta biblioteka, taka jak Scikit-learn. Jest to bowiem zbyt rozległa dziedzina, oparta o bardzo różnorodne podejścia i rozwiązania, aby dało się ją zamknąć w jednej bibliotece ze spójnym interfejsem. Można jednak wyróżnić zbiór najpopularniejszych bibliotek. Co ważne, praktyczne systemy implementuje się jednak często od zera, pod konkretny problem.\n",
    "\n",
    "1. [Surprise](https://surpriselib.com/) - od niedawna `scikit-surprise` ze względu na implementację interfejsów ze Scikit-learn'a. Implementuje algorytmy typu _explicit rating collaborative filtering_.\n",
    "2. [Implicit](https://benfred.github.io/implicit/) - podobna do Surprise, implementuje algorytmy typu _implicit rating collaborative filtering_.\n",
    "3. [LibRecommender](https://github.com/massquantity/LibRecommender) - rozbudowana biblioteka, implementująca różne podejścia: collaborative filtering, feature-based oraz hybrydowe. Zawiera algorytmy pisane od zera - w TensorFlow (niestety v1) oraz w PyTorchu - z wielu artykułów naukowych. Ma jednak dość specyficzny, niekoniecznie intuicyjny interfejs.\n",
    "4. [Spark MLlib](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html) - de facto standard w pracy z wielkimi zbiorami danych, częstymi w systemach rekomendacyjnych. Implementuje explicit oraz implicit collaborative filtering.\n",
    "5. [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) - de facto standard dla grafowych sieci neuronowych (Graph Neural Networks, **GNNs**), które są m. in. najnowszym trendem w systemach rekomendacyjnych opartych o grafy (_graph-based recommender systems_).\n",
    "\n",
    "Dodatkowo, dla podejścia content-based (opisane, ale nieimplementowane w tym laboratorium) można użyć dowolnej biblioteki do uczenia nadzorowanego, typowo Scikit-learn'a lub Spark MLlib.\n",
    "\n",
    "Na tym laboratorium wykorzystamy `Surprise` ze względu na prostotę użycia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "7yEcAeYIZuTk",
    "tags": []
   },
   "source": [
    "# Ściąganie, ładowanie i eksploracja danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "eetLwVSSZuTk",
    "tags": []
   },
   "source": [
    "Na początek ściągniemy nasz zbiór danych. Będziemy pracować na zbiorze MovieLens-100k, czyli zbiorze 100 tysięcy ocen filmów. Strona MovieLens udostępnia wiele rozmiarów tego zbioru danych, a ten będzie odpowiednio szybki na potrzeby edukacyjne. W praktyce wykorzystuje się zbiory rozmiaru co najmniej takiego, jak MovieLens-1M (zbiór miliona ocen).\n",
    "\n",
    "Opis plików można znaleźć w [README](https://files.grouplens.org/datasets/movielens/ml-100k-README.txt). Najważniejsze fragmenty:\n",
    "```\n",
    "u.data     -- The full u data set, 100000 ratings by 943 users on 1682 items.\n",
    "              Each user has rated at least 20 movies.  Users and items are\n",
    "              numbered consecutively from 1.  The data is randomly\n",
    "              ordered. This is a tab separated list of\n",
    "\t         user id | item id | rating | timestamp.\n",
    "              The time stamps are unix seconds since 1/1/1970 UTC   \n",
    "```\n",
    "\n",
    "Zbiór co prawda ma już przygotowany podział do 5-krotnej walidacji skrośnej (pliki `u1.base`, `u1.test` etc.), ale my wykonamy ten podział sami. Gotowych podziałów używa się w pracach naukowych, aby móc porównywać wyniki różnych algorytmów na dokładnie tych samych zbiorach treningowych i testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqeYrXAUZuTk",
    "outputId": "315920ec-3b07-4c2e-fb34-f9eaaedf11e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-30 11:53:16--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4924029 (4.7M) [application/zip]\n",
      "Saving to: ‘ml-100k.zip’\n",
      "\n",
      "ml-100k.zip         100%[===================>]   4.70M  10.0MB/s    in 0.5s    \n",
      "\n",
      "2025-01-30 11:53:17 (10.0 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -N https://files.grouplens.org/datasets/movielens/ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YizgaTthZuTl",
    "outputId": "2ae1f4ee-3aad-4e73-e3e1-b4d59de46880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "!unzip -n ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GGWmm7FsZuTl",
    "outputId": "5ba4fc05-9667-4c08-fecb-30e945fe1c5c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 266,\n        \"min\": 1,\n        \"max\": 943,\n        \"num_unique_values\": 943,\n        \"samples\": [\n          262,\n          136,\n          821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 330,\n        \"min\": 1,\n        \"max\": 1682,\n        \"num_unique_values\": 1682,\n        \"samples\": [\n          1557,\n          808,\n          1618\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5343856,\n        \"min\": 874724710,\n        \"max\": 893286638,\n        \"num_unique_values\": 49282,\n        \"samples\": [\n          889728713,\n          888443306,\n          880605158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e80eedfb-f90e-4d1f-a301-dd34cd28d179\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e80eedfb-f90e-4d1f-a301-dd34cd28d179')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e80eedfb-f90e-4d1f-a301-dd34cd28d179 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e80eedfb-f90e-4d1f-a301-dd34cd28d179');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-37f7d40b-0c60-42bc-91fc-6144ff210b7e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37f7d40b-0c60-42bc-91fc-6144ff210b7e')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-37f7d40b-0c60-42bc-91fc-6144ff210b7e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\"ml-100k\", \"u.data\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"],\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlVjFmgKZuTl",
    "outputId": "3a8fd417-2571-4482-f895-fcaedd58d85b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 100000\n",
      "Ratings range: (1, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of reviews: {len(df)}\")\n",
    "print(f\"Ratings range: {df.rating.min(), df.rating.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTCXyRkuZuTl"
   },
   "source": [
    "Tabela w formacie jak powyżej to de facto słownik `(user_id, item_id) -> rating`. Jest zatem idealna do podejścia collaborative filtering, w którym dla **użytkowników (users)** mamy ich **oceny (ratings)** wybranych **przedmiotów (items)**. Tutaj oczywiście przedmiotami są filmy. Można by zatem z takich danych zbudować **macierz ocen (ratings matrix)**, w której wiersze byłyby użytkownikami, kolumny przedmiotami, a komórki zawierałyby oceny.\n",
    "\n",
    "![Rating-matrix-representation-of-recommendation-data.png](attachment:Rating-matrix-representation-of-recommendation-data.png)\n",
    "\n",
    "W przyszłości chcemy zatem **przewidywać wartości brakujące** macierzy ocen. Mamy tu zatem poniekąd problem regresji - chcemy dostać wartość ciągłą, np. na ile użytkownik oceniłby film, którego jeszcze nie widział. Późniejsza rekomendacja to po prostu wybranie najwyższych predykcji i zaproponowanie tych właśnie przedmiotów. Nazywa się to czasem problemem **uzupełnienia macierzy (matrix completion)**.\n",
    "\n",
    "W praktyce **nigdy** nie należy budować macierzy ocen explicite. Zwyczajnie nie zmieściłaby się ona do pamięci dla zbiorów o prawdziwym rozmiarze, kiedy mamy setki tysięcy użytkowników i przedmiotów. Dodatkowo zwyczajnie nie ma to sensu, bo nasze macierze prawie zawsze są **rzadkie (sparse)**, tzn. mają wypełnioną tylko nieznaczną liczbę pól. Reszta jest nieznana - w końcu pojedynczy człowiek obejrzy tylko niewielką część wszystkich filmów z Netflixa, nie mówiąc już o wystawieniu im ocen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "xDab6yOpZuTl",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 1 (0.5 punktu)\n",
    "\n",
    "Oblicz gęstość (_density_) macierzy ocen dla naszego zbioru danych. Jest to liczba ocen podzielona przez rozmiar macierzy ocen (liczba użytkowników * liczba przedmiotów). Wynik przedstaw w procentach, zaokrąglony do 4 miejsc po przecinku. Pamiętaj, żeby uwzględnić tylko unikatowych użytkowników i przedmioty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaxBRiNVZuTm",
    "outputId": "89bc6aca-df09-42bf-8611-1b2821048f77",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gęstość macierzy ocen: 6.3047%\n"
     ]
    }
   ],
   "source": [
    "# your_code\n",
    "density = 100 * len(df) / (len(pd.unique(df[\"user_id\"])) * len(pd.unique(df[\"item_id\"])))\n",
    "\n",
    "print(f\"Gęstość macierzy ocen: {density:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Mjxq_OULZuTm",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "assert 6 <= density <= 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xuzNo8zZuTm",
    "tags": []
   },
   "source": [
    "W praktyce często zbiory mają gęstość rzędu 1% lub mniejszą. Jest to też pozytywne - w końcu to dzięki temu mamy komu robić rekomendacje (i czego).\n",
    "\n",
    "Warto zauważyć, że nasz zbiór zawiera tylko tych użytkowników, którzy ocenili przynajmniej 20 filmów, a zatem wiemy o każdym z nich całkiem sporo. Unika to problemu **zimnego startu (cold start)**, w którym nic nie wiemy o nowych użytkownikach i/lub filmach. W prawdziwych systemach jest to jednak duże wyzwanie. Można sobie z nim radzić na kilka sposobów:\n",
    "- rekomendować najpopularniejsze przedmioty,\n",
    "- rekomendować przedmioty o najwyższych ocenach,\n",
    "- użyć globalnego (niepersonalizowanego) systemu rekomendacyjnego, np. przewidywanie średniej dla przedmiotu,\n",
    "- używać systemu content-based, bo takie systemy radzą sobie dobrze przy małej liczbie interakcji,\n",
    "- poprosić użytkownika przy pierwszym logowaniu o podanie pierwszych preferencji (nie zawsze możliwe).\n",
    "\n",
    "W związku z problemem zimnego startu systemy rekomendacyjne zwykle są (co najmniej) dwuetapowe i mają osobny algorytm dla nowych użytkowników/przedmiotów oraz osobny dla tych, o których już coś wiemy więcej i możemy dokonywać personalizacji.\n",
    "\n",
    "Zbadajmy teraz rozkład popularności poszczególnych przedmiotów w naszym zbiorze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "PNERSMN1ZuTm",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 2 (0.5 punktu)\n",
    "\n",
    "Narysuj wykres popularności (liczby ocen) dla poszczególnych przedmiotów. Użyj odpowiednio dużej liczby kubełków histogramu, żeby zwizualizować kształt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "MyQQ4uQ3ZuTm",
    "outputId": "3fa1c589-3a8e-4c5b-e533-df0510312bb2",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your_code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_pivoted = pd.pivot_table(data=df, values=\"user_id\", index=\"item_id\", aggfunc=\"count\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Wykres popularności dla poszczególnych przedmiotów\")\n",
    "plt.ylabel(\"Liczba ocen\")\n",
    "plt.xlabel(\"ID przedmiotu\")\n",
    "plt.hist(df_pivoted, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtS5u_ynZuTm"
   },
   "source": [
    "Typowo niewielka liczba przedmiotów odpowiada za większość ocen. Są to rzeczy bardzo znane i popularne, napędzane efektem kuli śnieżnej. Przykładowo, \"Titanic\" ogląda i ocenia bardzo znaczna liczba użytkowników, przez sam fakt, jak bardzo znany jest ten film. My jesteśmy zwykle zainteresowani **długim ogonem (long tail)** naszego rozkładu popularności, czyli zwiększeniem popularności tych przedmiotów, które są mniej znane, a które możemy zaoferować użytkownikom, np. nowa muzyka do odkrycia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gb0nvj7ZuTm"
   },
   "source": [
    "**Eksploracja danych - podsumowanie**\n",
    "\n",
    "1. W systemach typu collaborative filtering operujemy na macierzy ocen, gdzie wierszami są użytkownicy, kolumnami przedmioty, a w komórkach znajdują się oceny.\n",
    "2. Macierz ocen jest zwykle _bardzo_ rzadka.\n",
    "3. Kiedy niewiele wiemy o użytkowniku lub przedmiocie, to mamy tzw. problem _zimnego startu_, z którym trzeba sobie w jakiś sposób poradzić.\n",
    "4. Często występuje zjawisko **długiego ogona**, czyli dominacji niewielkiej grupy bardzo popularnych przedmiotów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "6VvpJt0cZuTm",
    "tags": []
   },
   "source": [
    "# Walidacja modeli, prosty model bazowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "GPaR3o2PZuTm",
    "tags": []
   },
   "source": [
    "Na początek, zanim zaczniemy budować nasze modele, trzeba wyodrębnić zbiór testowy. Mamy tutaj kilka możliwości. Po pierwsze, można po prostu losowo, tak jak to robiliśmy do tej pory i tak bardzo często się robi.\n",
    "\n",
    "Zbiór testowy ma jednak symulować przyszłe dane, przybliżać zdolność generalizacji modelu, a my mamy do dyspozycji znaczniki czasowe, z kiedy pochodzą dane oceny. Możnaby więc użyć **podziału czasowego (time split)**, czyli wyodrębnić najnowsze oceny do zbioru testowego, a konkretnie najnowsze oceny per użytkownik. Stanowi to bardzo dobrą symulację tego, jak w praktyce działa system.\n",
    "\n",
    "Powyższe podejścia mają jednak pewne ryzyko - może się zdarzyć, że tak wylosujemy zbiór testowy, że dla jakiegoś użytkownika 90% ocen jest w zbiorze testowym, więc spowodujemy u niego przypadkiem problem zimnego startu. Analogicznie może być przy podziale czasowym, kiedy jakiś nowy użytkownik był aktywny tylko niedawno i być może nawet wszystkie jego predykcje trafiłyby do zbioru testowego. Dlatego można stosować **podział per użytkownik**, wyodrębniając np. losowe 10% ocen każdego użytkownika jako zbiór testowy.\n",
    "\n",
    "Jak widać, jest tu nieco ciężej niż przy zwykłej klasyfikacji czy regresji. Dla uproszczenia wykorzystamy zwykły podział losowy. Implementacje innych metod można znaleźć np. w bibliotece _LibRecommender_.\n",
    "\n",
    "Surprise definiuje 2 ważne klasy: `Dataset` i `Trainset`. Ta pierwsza reprezentuje surowe dane, a druga wstępnie przetworzone dane do treningu lub testowania. Interfejs jest tutaj dość dziwny, ale w skrócie:\n",
    "- do zwykłych algorytmów idą `train_set` i `test_set`,\n",
    "- do `GridSearchCV` idą `data_train` i `test_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPtaC5q6wMPQ",
    "outputId": "79f494e2-cce5-4519-8832-79ae53c14989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505174 sha256=3815f1eebde0981afca3b6f8ceb31874b859b768a4c3ea0f64b9ecb84d207aed\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.4\n"
     ]
    }
   ],
   "source": [
    "# dodane na potrzeby zainstalowania biblioteki\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bnPvHUppZuTn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.dataset import Dataset, Reader\n",
    "\n",
    "reader = Reader(rating_scale=(df[\"rating\"].min(), df[\"rating\"].max()))\n",
    "dataset = Dataset.load_from_df(df[[\"user_id\", \"item_id\", \"rating\"]], reader=reader)\n",
    "\n",
    "ratings_train, ratings_test = train_test_split(\n",
    "    dataset.raw_ratings, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "data_train = deepcopy(dataset)\n",
    "data_train.raw_ratings = ratings_train\n",
    "\n",
    "train_set = data_train.build_full_trainset()\n",
    "test_set = data_train.construct_testset(ratings_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC7c5s7kZuTn",
    "tags": []
   },
   "source": [
    "Na początek zaimplementujemy model, który przewiduje po prostu wartość średnią dla każdego przedmiotu. Nie ma on żadnych hiperparametrów, więc nawet nie będziemy potrzebować zbioru walidacyjnego. Jest to bardzo dobry **model bazowy (baseline)** w systemach rekomendacyjnych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "pdEy2TT1ZuTn",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 3 (1 punkt)\n",
    "\n",
    "Uzupełnij kod klasy `ItemAveragePredictor`, która przewiduje wartość średnią dla każdego przedmiotu. Może ci się tutaj przydać atrybut `ir` (item rating) klasy `Trainset` - [dokumentacja tej klasy](https://surprise.readthedocs.io/en/stable/trainset.html), oraz [dokumentacja tworzenia własnych algorytmów](https://surprise.readthedocs.io/en/stable/building_custom_algo.html).\n",
    "\n",
    "Dobrym pomysłem będzie przechowywanie danych w postaci atrybutu będącego słownikiem w `.fit()`, żeby zapamiętać mapowanie `item_id` -> średnia ocena.\n",
    "\n",
    "Uwaga - zgodnie z konwencją z Scikit-learn'a atrybuty, których wartości są obliczane (estymowane) na podstawie danych treningowych, są tworzone w metodzie `.fit()` i mają underscore (`_`) na końcu nazwy, np. `self.ratings_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EoFJnbZaZuTn",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from surprise import AlgoBase, PredictionImpossible\n",
    "\n",
    "class ItemAveragePredictor(AlgoBase):\n",
    "    def __init__(self):\n",
    "        AlgoBase.__init__(self)\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "\n",
    "        # mapping: item_id -> average rating\n",
    "        # compute average rating for each item\n",
    "        # your_code\n",
    "        self.ratings_ = {}\n",
    "        irs = self.trainset.ir\n",
    "\n",
    "        for item_id, ratings in irs.items():\n",
    "            self.ratings_[item_id] = np.mean([rating[1] for rating in ratings])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible(\"User and/or item is unknown.\")\n",
    "\n",
    "        return self.ratings_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMZtDMxzZuTn",
    "outputId": "c37ac0f7-c615-4e47-a999-f0d3dc0cb3ae",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=508, iid=185, r_ui=5.0, est=4.075376884422111, details={'was_impossible': False}),\n",
       " Prediction(uid=518, iid=742, r_ui=5.0, est=3.632850241545894, details={'was_impossible': False}),\n",
       " Prediction(uid=178, iid=28, r_ui=5.0, est=3.897777777777778, details={'was_impossible': False}),\n",
       " Prediction(uid=899, iid=291, r_ui=4.0, est=3.4591836734693877, details={'was_impossible': False}),\n",
       " Prediction(uid=115, iid=117, r_ui=4.0, est=3.664451827242525, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = ItemAveragePredictor()\n",
    "algo.fit(train_set)\n",
    "\n",
    "pred_item_avg = algo.test(test_set)\n",
    "pred_item_avg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uxV6V55FZuTn",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "assert 3.45 <= np.mean([pred.est for pred in pred_item_avg]) <= 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFIgr_t6ZuTn"
   },
   "source": [
    "Musimy teraz ocenić jakość naszego algorytmu. Jako że mamy tu problem regresji, to naturalnym wyborem są **RMSE (root mean squared error)** oraz **MAE (Mean Absolute Error)**. Pokażą nam one, jak bardzo (średnio) nasz model myli się w przewidywaniu ratingu.\n",
    "\n",
    "RMSE to po prostu pierwiastek błędu średniokwadratowego (MSE). Ma taką samą wadę przy ewaluacji jak MSE - zwraca zbyt dużą uwagę na obserwacje odstające (outliers). Dzięki pierwiastkowaniu ma tę samą jednostkę, co oryginalne dane.\n",
    "$$\\large\n",
    "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N \\left( y_i - \\hat{y}_i \\right)^2}\n",
    "$$\n",
    "\n",
    "MAE to średnie odchylenie predykcji od wartości prawdziwej. Dzięki zastosowaniu wartości bezwzględnej zamiast kwadratu jest miarą bardziej odporną na outliery i dlatego często wykorzystywaną przy ewaluacji. Ma naturalnie tę samą jednostkę, co mierzona wartość.\n",
    "$$\\large\n",
    "MAE = \\frac{1}{N} \\sum_{i=1}^N \\left| y_i - \\hat{y}_i \\right|\n",
    "$$\n",
    "\n",
    "Ze względu na to, że Surprise nie zwraca zwykłego wektora NumPy'a, tylko obiekty `Prediction`, trzeba użyć metryk z tej biblioteki - albo zaimplementować własne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwgBwtWIZuTo",
    "outputId": "c5cc1c81-ec78-41b4-9bb0-e38060c04452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0231\n",
      "MAE:  0.8153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8153345185529649"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.accuracy import rmse, mae\n",
    "\n",
    "rmse(pred_item_avg, verbose=True)\n",
    "mae(pred_item_avg, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCV0AKH-ZuTo"
   },
   "source": [
    "Wygląda na to, że nawet najprostszy model nie radzi sobie wcale tak źle. Ale są to tylko przewidywane wartości - zobaczmy faktyczne rekomendacje. W praktyce mamy ograniczone miejsce, np. mało kto popatrzy na więcej niż pierwsze 5-10 rekomendowanych filmów. W związku z tym nieważne nawet, co będzie dalej - liczy się dla nas **top k** predykcji.\n",
    "\n",
    "Zgromadzimy teraz faktyczne najlepsze oceny ze zbioru testowego dla każdego użytkownika, rekomendacje naszego systemu i zbierzemy je w jeden DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "JT5Ba48nZuTo",
    "outputId": "76a92c5b-cf18-44ee-c704-521e2cb130c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"rec_item_avg\",\n  \"rows\": 941,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 272,\n        \"min\": 1,\n        \"max\": 943,\n        \"num_unique_values\": 941,\n        \"samples\": [\n          335,\n          585,\n          409\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recommendations\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "rec_item_avg"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ac433869-2436-44d8-b57e-e76424f2843b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[186, 122, 182, 81, 83, 249, 48, 116, 90, 94, ...</td>\n",
       "      <td>[64, 136, 174, 48, 23, 83, 242, 74, 182, 238, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[255, 251, 242, 10, 1, 285, 258, 283, 257, 269...</td>\n",
       "      <td>[251, 285, 127, 242, 269, 1, 10, 258, 257, 283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[288, 355, 320, 343, 341, 342, 326]</td>\n",
       "      <td>[320, 288, 326, 341, 343, 355, 342, 970, 976, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[258, 361]</td>\n",
       "      <td>[258, 361, 975, 973, 972, 971, 970, 969, 968, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[401, 413, 21, 194, 227, 40, 408, 151, 243, 38...</td>\n",
       "      <td>[408, 173, 194, 189, 216, 144, 1, 200, 204, 37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>[9, 409, 689, 1190, 471, 118, 222]</td>\n",
       "      <td>[9, 222, 471, 1190, 118, 689, 409, 967, 973, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>[147, 95, 98, 357, 471, 382, 1167, 164, 527, 2...</td>\n",
       "      <td>[285, 357, 98, 427, 172, 651, 527, 430, 213, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>[117]</td>\n",
       "      <td>[117, 1, 996, 971, 970, 969, 968, 967, 966, 96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>[282, 945, 969, 661, 500, 304, 323, 272, 604, ...</td>\n",
       "      <td>[318, 272, 480, 313, 479, 528, 520, 661, 659, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>[1044, 12, 54, 231, 230, 449, 570, 68, 431, 19...</td>\n",
       "      <td>[50, 12, 22, 195, 182, 210, 69, 97, 282, 92, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac433869-2436-44d8-b57e-e76424f2843b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ac433869-2436-44d8-b57e-e76424f2843b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ac433869-2436-44d8-b57e-e76424f2843b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ac6971d5-581d-4c62-b233-4cc12f196d11\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac6971d5-581d-4c62-b233-4cc12f196d11')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ac6971d5-581d-4c62-b233-4cc12f196d11 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_0b3a43fe-3601-44ef-aa63-b41b3527decd\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rec_item_avg')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_0b3a43fe-3601-44ef-aa63-b41b3527decd button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('rec_item_avg');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                    actual  \\\n",
       "user_id                                                      \n",
       "1        [186, 122, 182, 81, 83, 249, 48, 116, 90, 94, ...   \n",
       "2        [255, 251, 242, 10, 1, 285, 258, 283, 257, 269...   \n",
       "3                      [288, 355, 320, 343, 341, 342, 326]   \n",
       "4                                               [258, 361]   \n",
       "5        [401, 413, 21, 194, 227, 40, 408, 151, 243, 38...   \n",
       "...                                                    ...   \n",
       "939                     [9, 409, 689, 1190, 471, 118, 222]   \n",
       "940      [147, 95, 98, 357, 471, 382, 1167, 164, 527, 2...   \n",
       "941                                                  [117]   \n",
       "942      [282, 945, 969, 661, 500, 304, 323, 272, 604, ...   \n",
       "943      [1044, 12, 54, 231, 230, 449, 570, 68, 431, 19...   \n",
       "\n",
       "                                           recommendations  \n",
       "user_id                                                     \n",
       "1        [64, 136, 174, 48, 23, 83, 242, 74, 182, 238, ...  \n",
       "2        [251, 285, 127, 242, 269, 1, 10, 258, 257, 283...  \n",
       "3        [320, 288, 326, 341, 343, 355, 342, 970, 976, ...  \n",
       "4        [258, 361, 975, 973, 972, 971, 970, 969, 968, ...  \n",
       "5        [408, 173, 194, 189, 216, 144, 1, 200, 204, 37...  \n",
       "...                                                    ...  \n",
       "939      [9, 222, 471, 1190, 118, 689, 409, 967, 973, 9...  \n",
       "940      [285, 357, 98, 427, 172, 651, 527, 430, 213, 2...  \n",
       "941      [117, 1, 996, 971, 970, 969, 968, 967, 966, 96...  \n",
       "942      [318, 272, 480, 313, 479, 528, 520, 661, 659, ...  \n",
       "943      [50, 12, 22, 195, 182, 210, 69, 97, 282, 92, 3...  \n",
       "\n",
       "[941 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Prediction\n",
    "\n",
    "def get_user_recommendations(user_rec_items: pd.Series) -> list[int]:\n",
    "    return user_rec_items.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "def get_recommendations(predictions: list[Prediction]) -> pd.DataFrame:\n",
    "    df_pred = pd.DataFrame(predictions)\n",
    "    df_pred = df_pred.drop(columns=\"details\")\n",
    "    df_pred.columns = [\"user_id\", \"item_id\", \"actual\", \"prediction\"]\n",
    "\n",
    "    df = (\n",
    "        df_pred.groupby(\"user_id\", as_index=False)[\"item_id\"]\n",
    "        .agg({\"actual\": (lambda x: list(x))})\n",
    "        .set_index(\"user_id\")\n",
    "    )\n",
    "\n",
    "    df_pivot = df_pred.pivot_table(\n",
    "        index=\"user_id\", columns=\"item_id\", values=\"prediction\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    df[\"recommendations\"] = [\n",
    "        get_user_recommendations(df_pivot.loc[user_id]) for user_id in df.index\n",
    "    ]\n",
    "\n",
    "    return df\n",
    "\n",
    "rec_item_avg = get_recommendations(pred_item_avg)\n",
    "rec_item_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "aznm4ngUZuTo",
    "tags": []
   },
   "source": [
    "Teraz, kiedy można porównać faktyczne predykcje, patrząc np. na top 5, to nie wygląda to już tak dobrze, jak trzeba wybrać konkretne filmy. Do mierzenia jakości wśród top k predykcji służą metryki:\n",
    "- Mean Average Precision at k (MAP@k),\n",
    "- Mean Average Recall at k (MAR@k),\n",
    "- Fraction of Concordant Pairs (FCP),\n",
    "- Normalized Discounted Cumulative Gain (NDCG).\n",
    "\n",
    "Są one używane w systemach rekomendacyjnych, ale też w wyszukiwarkach i niektórych problemach NLP. Dla MAP i MAR dokładny opis (krok po kroku) możesz znaleźć [tutaj](https://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html) i [pod tym linkiem](https://machinelearninginterview.com/topics/machine-learning/mapatk_evaluation_metric_for_ranking/). FCP doskonale opisuje [oryginalny artykuł](https://www.ijcai.org/Proceedings/13/Papers/449.pdf). [Tutaj](https://finisky.github.io/2019/04/24/ndcg/) z kolei krótki i treściwy artykuł o NDCG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "WVWmlZDUZuTo",
    "tags": []
   },
   "source": [
    "## MAP@k\n",
    "\n",
    "Zdefiniujmy:\n",
    "- True Positive (TP) - przedmiot, który naprawdę jest w top k (*relevant*) i który nasz system zarekomendował w top k przedmiotów,\n",
    "- False Positive (FP) - przedmiot, który nie jest w top k (*nonrelevant*), ale nasz model go zarekomendował w top k.\n",
    "\n",
    "\"Precision at k\" to precyzja (_precision_), obliczona dla top k przedmiotów. Oznaczmy przez $r_k$ liczbę TP (*relevant items*) wśród top k przedmiotów.\n",
    "\n",
    "$$\\large\n",
    "P@k = \\frac{\\text{number of relevant items in top }k}{k} = \\frac{r_k}{k}\n",
    "$$\n",
    "\n",
    "\"Average P@k\" to po prostu P@k obliczone dla różnych $i=1,2,...,k$ i uśrednione. Taka agregacja bardzo penalizuje umieszczanie nieciekawych przedmiotów na wysokich miejscach, bo uwzględniamy tylko precyzję dla tych top k, gdzie prawidłowo zauważyliśmy TP.\n",
    "\n",
    "$$\\large\n",
    "AP@k = \\frac{1}{r_k} \\sum_{i=1}^{k} \\left( P@i \\text{ if i-th item is relevant} \\right)\n",
    "$$\n",
    "\n",
    "MAP@k to AP@k (Average Precision at k), uśrednione dla wszystkich $|U|$ użytkowników:\n",
    "\n",
    "$$\\large\n",
    "MAP@k = \\frac{1}{|U|} \\sum_{u=1}^{|U|}AP@k(u)\n",
    "$$\n",
    "\n",
    "Im niższe $k$, tym surowsi jesteśmy i tym niższe będą wyniki - nasz algorytm ma mniej miejsca na błąd. Typowo $k=5$ lub $k=10$. Zakres wartości MAP@k to $[0; 1]$.\n",
    "\n",
    "MAP@k przykłada bardzo dużą wagę do tego, żeby na pierwszych miejscach trafiły się jak najlepsze przedmioty. Jest zatem bardzo ważne, kiedy mamy mało miejsc do dyspozycji, np. przy rekomendacji filmów na głównej stronie (Netflix).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "zhAQdQqbZuTo",
    "tags": []
   },
   "source": [
    "## FCP\n",
    "\n",
    "FCP (Fraction of Concordant Pairs) jest rzadziej używaną, ale bardzo intuicyjną metryką. Ideą jest uogólnienie metryki AUROC (ROC AUC) na algorytmy rankujące, a więc systemy rekomendacyjne. Ma zakres wartości także $[0; 1]$.\n",
    "\n",
    "Liczba zgodnych par (*concordant pairs*) $n_c^u$ dla użytkownika $u$ to liczba par przedmiotów, które zostały prawidłowo uporządkowane przez _ranker_. Innymi słowy, gdy mamy prawdziwy ranking ocen użytkownika oraz przewidywany, to jest to liczba par przedmiotów, które prawidłowo ułożyliśmy (lepszy przedmiot jest wyżej niż gorszy).\n",
    "\n",
    "$$\\large\n",
    "n_c(u) = |\\{ (i,j) | \\hat{r}_{ui} > \\hat{r}_{uj} \\text{ and } r_{ui} > r_{uj}\\}|\n",
    "$$\n",
    "\n",
    "Pary niezgodne (*discordant pairs*) liczy się podobnie:\n",
    "\n",
    "$$\\large\n",
    "n_d(u) = |\\{ (i,j) | \\hat{r}_{ui} > \\hat{r}_{uj} \\text{ and } r_{ui} \\leq r_{uj}\\}|\n",
    "$$\n",
    "\n",
    "Proporcja par zgodnych do wszystkich, zsumowana dla wszystkich użytkowników, to właśnie FCP:\n",
    "\n",
    "$$\\large\n",
    "FCP = \\frac{n_c}{n_c + n_d} = \\frac{\\sum_{i=1}^n n_c(u)}{\\sum_{i=1}^n n_c(u) + n_d(u)}\n",
    "$$\n",
    "\n",
    "Można także obliczyć FCP@k, ograniczając się do pierwszych k predykcji.\n",
    "\n",
    "Metryka FCP przykłada mniejszą wagę niż MAP@k do tego, żeby najlepsze przedmioty były jak najwyżej. Skupia się natomiast na tym, żeby lepsze przedmioty były powyżej gorszych. Działa więc lepiej dla rekomendacji dłuższych list, kiedy pierwsze pozycje nie są aż tak ważne, np. przy rekomendowaniu playlist muzyki (Spotify)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "m9lgNK3TZuTo",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 4 (1 punkt)\n",
    "\n",
    "Uzupełnij kod funkcji `ap_k`, która oblicza AP@k dla pojedynczego użytkownika. Pamiętaj, aby ograniczyć się do najwyższych (pierwszych) `k` przedmiotów dla rekomendacji oraz predykcji. W przypadku, gdy model nie miał żadnej dobrej predykcji ($r_k = 0$), zwróć 0.\n",
    "\n",
    "Następnie oblicz i wypisz MAP@k oraz FCP ($k=10$) dla naszego modelu średniej przedmiotu. Wartości podaj w procentach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0ROYIDrbZuTo",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "def ap_k(y_true: list[int], y_pred: list[int], k: int) -> float:\n",
    "    # your_code\n",
    "    true_k = y_true[:k]\n",
    "    pred_k = y_pred[:k]\n",
    "\n",
    "    relevant = 0\n",
    "    score = 0.0\n",
    "\n",
    "    for i, pred in enumerate(pred_k):\n",
    "        if pred in true_k:\n",
    "            relevant += 1\n",
    "            score += relevant / (i + 1)\n",
    "\n",
    "    return 0.0 if relevant == 0 else score / relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Sq7tRlENZuTo",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from surprise.accuracy import fcp\n",
    "\n",
    "def map_k(df: pd.DataFrame, k: int) -> float:\n",
    "    ap_k_values = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        actual, recommendations = row\n",
    "        ap_k_val = ap_k(actual, recommendations, k)\n",
    "        ap_k_values.append(ap_k_val)\n",
    "\n",
    "    return np.mean(ap_k_values)\n",
    "\n",
    "def fcp_k(predictions: list[Prediction], k: int) -> float:\n",
    "    top_k = defaultdict(list)\n",
    "\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_k[uid].append((iid, est))\n",
    "\n",
    "    user_item_id_pairs = set()\n",
    "\n",
    "    for user_id, user_ratings in top_k.items():\n",
    "        user_ratings.sort(key=itemgetter(1), reverse=True)\n",
    "\n",
    "        for item_id, rating in user_ratings[:k]:\n",
    "            user_item_id_pairs.add((user_id, item_id))\n",
    "\n",
    "    predictions_top_k = [\n",
    "        pred for pred in predictions if (pred[0], pred[1]) in user_item_id_pairs\n",
    "    ]\n",
    "\n",
    "    return fcp(predictions_top_k, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT6RkV-jZuTp",
    "outputId": "c9966550-ec36-4c61-87d4-fe2e727ac609",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item average model MAP@k (k=10): 74.55%\n",
      "Item average model FCP@k (k=10): 60.60%\n"
     ]
    }
   ],
   "source": [
    "map_k_item_avg = map_k(rec_item_avg, k=10)\n",
    "fcp_item_avg = fcp_k(pred_item_avg, k=10)\n",
    "\n",
    "print(f\"Item average model MAP@k (k=10): {100 * map_k_item_avg:.2f}%\")\n",
    "print(f\"Item average model FCP@k (k=10): {100 * fcp_item_avg:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZWb0cciEZuTy",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "assert 0.73 <= map_k_item_avg <= 0.75\n",
    "assert 0.59 <= fcp_item_avg <= 0.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE0iqfrKZuTy"
   },
   "source": [
    "Zobaczymy, że ten wynik da się jeszcze poprawić.\n",
    "\n",
    "Metryki MAP@k i MAR@k mają jednak pewną wadę - preferują sugerowanie popularnych treści przez model, bo można je łatwo umieścić wysoko w rekomendacji i łatwo podbić sobie precyzję. W ten sposób rekomendacje byłyby słabo personalizowane. Dlatego wykorzystuje się szereg innych metryk, głównie biorących pod uwagę różnorodność i personalizację rekomendacji, na przykład:\n",
    "- pokrycie (*coverage*) - procent przedmiotów ze zbioru, które nasz system w ogóle rekomenduje,\n",
    "- nowość (*novelty*) - zdolność systemu do rekomendacji zaskakujących, nowych dla użytkownika przedmiotów,\n",
    "- personalizacja (*personalization*) - miara różnicy między rekomendacjami dla poszczególnych użytkowników.\n",
    "\n",
    "Możesz o nich poczytać więcej [w tym artykule](https://towardsdatascience.com/evaluation-metrics-for-recommender-systems-df56c6611093)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_331wgg9ZuTy"
   },
   "source": [
    "**Pomiar jakości systemów rekomendacyjnych - podsumowanie**\n",
    "\n",
    "1. Poza stosowaniem zwykłego podziału losowego train-test, można też stosować podział czasowy lub per użytkownik.\n",
    "2. Jednym z najprostszych modeli i dobrym punktem odniesienia (baseline) jest przewidywanie średniej per przedmiot.\n",
    "3. Podstawowymi metrykami jakości są metryki dla regresji: RMSE i MAE oraz rankowania: MAP@k, MAR@k, NDCG.\n",
    "4. Inne metryki, specyficzne dla rekomendacji, biorą pod uwagę jakość personalizowanych rekomendacji, np. pokrycie, nowość, personalizacja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "T7lRmswvZuTy",
    "tags": []
   },
   "source": [
    "# Model średniej bayesowskiej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "HtqymldLZuTz",
    "tags": []
   },
   "source": [
    "Masz ochotę na dobrą pizzę i szukasz opinii na Google Maps. Masz do wyboru 2 lokale: jeden ze średnią 5.0 i drugi ze średnią 4.8. Zauważasz jednak, że pierwszy ma tylko 5 opinii, a drugi 200. Który wybierzesz? Są spore szanse, że ten drugi, bo mamy większą **pewność (confidence)** co do oceny takiego lokalu.\n",
    "\n",
    "Prosty model, taki jak średnia przedmiotu, ma ten sam problem, co powyżej. Sformalizowaniem idei \"chcę być pewny, że ocena przedmiotu jest wysoka\" jest model **średniej bayesowskiej (Bayesian average)**. Możliwych sformułowań bayesowskich jest dużo, ale ogólna idea jest zawsze taka, aby wziąć pod uwagę rozkład ocen przedmiotu oraz ich liczbę. Co ważne, to dalej są rekomendacje globalne - mamy jedną predykcję per przedmiot.\n",
    "\n",
    "Czemu średnia \"bayesowska\"? Przypomnijmy sobie twierdzenie Bayesa:\n",
    "$$\\large\n",
    "P(Y|X) = \\frac{P(X|Y) \\cdot P(Y)}{P(X)}\n",
    "$$\n",
    "\n",
    "W naszym wypadku:\n",
    "1. $X$ - zbiór danych, który jest stały.\n",
    "2. $Y$ - przewidywane wartości.\n",
    "3. $P(X)$ - prawdopodobieństwo zaobserwowania naszych danych, które co prawda ciężko jest zmierzyć, ale na szczęście w ML zwykle możemy zignorować mianownik, bo to tylko stała.\n",
    "4. $P(Y)$ - prior (*prior distribution*), czyli z góry założony rozkład prawdopodobieństw wartości, które przewidujemy. Często zaczynamy bez żadnej wiedzy, więc zakładamy rozkład jednostajny lub normalny.\n",
    "5. $P(X|Y)$ - likelihood - _wiarygodność_, czyli jak dobrze model odwzorowuje dotychczas zaobserwowane dane.\n",
    "6. $P(Y|X)$ - posterior (*posterior distribution*), czyli docelowy rozkład wartości przewidywanych, obliczony na podstawie danych.\n",
    "\n",
    "W kontekście systemów rekomendacyjnych:\n",
    "- $P(Y)$ - prior - to założony z góry rozkład ocen, typowo jednostajny, czyli jest taka sama szansa na każdą ocenę,\n",
    "- $P(X|Y)$ - likelihood - to miara, jak dobrze nasz model odwzorowuje macierz ocen; jakbyśmy potraktowali go jako skrzynkę generującą oceny, to wiarygodność mierzy, jak bliskie są te generowane wartości wobec prawdziwych ze zbioru danych,\n",
    "- $P(Y|X)$ - posterior - to rozkład przewidywanych ocen dla poszczególnych przedmiotów.\n",
    "\n",
    "Jak widać, w wyniku dostajemy rozkład. Jak dostać konkretną predykcję, czyli np. liczbę gwiazdek? Używamy **maximum a posteriori (MAP)**, czyli bierzemy po prostu tę ocenę, dla której rozkład posterior ma największą wartość.\n",
    "\n",
    "Wykorzystamy podejście opisane krok po kroku [w tym artykule](https://fulmicoton.com/posts/bayesian_rating/) oraz [w tym tutorialu](https://www.algolia.com/doc/guides/managing-results/must-do/custom-ranking/how-to/bayesian-average/), w którym przewidywana ocena dla $i$-tego przedmiotu (po przekształceniach) to:\n",
    "\n",
    "$$\\large\n",
    "r_i = \\frac{C \\cdot m + \\text{suma ocen dla przedmiotu } i}{C + \\text{liczba ocen}},\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "- $m$ - prior, globalna średnia ocen dla wszystkich przedmiotów,\n",
    "- $C$ - confidence, liczba ocen dla przedmiotu.\n",
    "\n",
    "Dodatkowe źródła:\n",
    "- [artykuł o twierdzeniu Bayesa](https://towardsdatascience.com/understand-bayes-rule-likelihood-prior-and-posterior-34eae0f378c5),\n",
    "- [proste i przyjazne sformułowanie średniej bayesowskiej](https://arpitbhayani.me/blogs/bayesian-average),\n",
    "- [bardziej wyrafinowane podejście, oparte o dolną granicę błędu](https://www.evanmiller.org/how-not-to-sort-by-average-rating.html),\n",
    "- [bardzo wyrafinowane podejście, oparte o dolną granicę błędu - dla odważnych](https://www.evanmiller.org/ranking-items-with-star-ratings.html),\n",
    "- [średnia bayesowska dla danych zmiennych w czasie](https://www.evanmiller.org/bayesian-average-ratings.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "gSrJHxGLZuTz",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 5 (1 punkt)\n",
    "\n",
    "Uzupełnij kod klasy `BayesianAveragePredictor`. W metodzie `.fit()` musisz obliczyć parametry:\n",
    "- sumę ocen dla każdego przedmiotu,\n",
    "- liczbę ocen dla każdego przedmiotu,\n",
    "- globalną pewność (confidence, $C$).\n",
    "\n",
    "Pewność oblicz jako dolny kwartyl (25. percentyl) rozkładu liczby ocen przedmiotów, zgodnie z [tym tutorialem](https://www.algolia.com/doc/guides/managing-results/must-do/custom-ranking/how-to/bayesian-average/#how-to-calculate-the-bayesian-average). Przyda ci się funkcja `np.quantile()`.\n",
    "\n",
    "Sugerowane jest używanie słowników w `.fit()`, żeby mapować `item_id` na odpowiednią wartość.\n",
    "\n",
    "W metodzie `.estimate()` musisz zastosować obliczone parametry we wzorze podanym powyżej.\n",
    "\n",
    "Dokonaj predykcji i oblicz metryki za pomocą podanej funkcji. Skomentuj wynik w porównaniu do przewidywania średniej przedmiotu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ympVzR_TZuTz",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "class BayesianAveragePredictor(AlgoBase):\n",
    "    def __init__(self):\n",
    "        AlgoBase.__init__(self)\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "\n",
    "        self.global_avg_ = trainset.global_mean\n",
    "\n",
    "        # mapping: item_id -> sum of ratings\n",
    "        self.ratings_sums_ = dict()\n",
    "\n",
    "        # mapping: item_id -> number of ratings\n",
    "        self.ratings_counts_ = dict()\n",
    "\n",
    "        # compute rating sum and rating count for each item\n",
    "        # also calculate confidence (C)\n",
    "        # your_code\n",
    "        irs = self.trainset.ir\n",
    "\n",
    "        for item_id, ratings in irs.items():\n",
    "            self.ratings_counts_[item_id] = len(ratings)\n",
    "            self.ratings_sums_[item_id] = np.sum([rating[1] for rating in ratings])\n",
    "\n",
    "        self.confidence_ = np.quantile(list(self.ratings_counts_.values()), q=0.25)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible(\"User and/or item is unknown.\")\n",
    "\n",
    "        # compute score formula\n",
    "        # your_code\n",
    "        score = (\n",
    "            self.confidence_ * self.global_avg_ + self.ratings_sums_[i]\n",
    "        ) / (self.confidence_ + self.ratings_counts_[i])\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tnJMcZlFZuTz",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "def print_metrics(\n",
    "    predictions: list[Prediction], recommendations: pd.DataFrame, k: int = 10\n",
    ") -> None:\n",
    "    rmse(predictions, verbose=True)\n",
    "    mae(predictions, verbose=True)\n",
    "    map_k_value = map_k(recommendations, k=k)\n",
    "    fcp_k_value = fcp_k(predictions, k=k)\n",
    "\n",
    "    print(f\"MAP@k ({k=}): {100 * map_k_value:.2f}%\")\n",
    "    print(f\"FCP@k ({k=}): {100 * fcp_k_value:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5-_bjQWZuTz",
    "outputId": "7e936a98-ac57-490a-cfdd-2734bc806ffa",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0224\n",
      "MAE:  0.8166\n",
      "MAP@k (k=10): 74.44%\n",
      "FCP@k (k=10): 60.50%\n"
     ]
    }
   ],
   "source": [
    "algo = BayesianAveragePredictor()\n",
    "algo.fit(train_set)\n",
    "\n",
    "pred_bayes_avg = algo.test(test_set)\n",
    "rec_bayes_avg = get_recommendations(pred_bayes_avg)\n",
    "\n",
    "# calculate and print metrics\n",
    "print_metrics(pred_bayes_avg, rec_bayes_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sdbU5tR0ZuTz",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "assert 1 <= rmse(pred_bayes_avg, verbose=False) <= 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "4IflzuGXZuTz",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "//skomentuj tutaj\n",
    "\n",
    "Porównując wartości metryk _RMSE_ i _MAE_, są one bardzo podobne, jak przy przewidywaniu średniej przedmiotu - _RMSE_ jest trochę niższa, z kolei _MAE_ nieco wyższa (tutaj mniejsza wartość oznacza lepszy wynik).\n",
    "\n",
    "Podobnie jeżeli chodzi o wartości metryk **MAP@k** i **FCP@k** (tutaj z kolei wyższa wartość jest pożądana), to wartości obu są podobne zarówno w modelu przewidywania średniej przedmiotu, jak i dla modelu średniej Bayesowskiej.\n",
    "\n",
    "Patrząc na same metryki, nie widać znacznego ulepszenia w stosunku do modelu przewidywania średniej przedmiotu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "8xSbeCPcZuT0",
    "tags": []
   },
   "source": [
    "# Metody oparte o sąsiedztwo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "odaDP1I8ZuT0",
    "tags": []
   },
   "source": [
    "Mając solidne punkty odniesienia w postaci rekomendacji globalnych, możemy przejść do rekomendacji personalizowanych. W metodach **opartych o sąsiedztwo (neighborhood-based)** znajdujemy podobnych użytkowników do nas albo przedmioty podobne do tych, które lubiliśmy i na podstawie tego dokonujemy rekomendacji.\n",
    "\n",
    "Podejście to jest używane także w innych obszarach uczenia maszynowego, np. w algorytmie k najbliższych sąsiadów (*k nearest neighbors*, kNN), SMOTE albo w identyfikacji osób (znajdujemy 1 najbliższego sąsiada dla embeddingu twarzy). Wymaga ono odpowiedniej metryki, która zmierzy odległość między wektorami, znajdując k najbliższych sąsiadów, z których następnie wyciągamy informacje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "zRhfTBrEZuT0",
    "tags": []
   },
   "source": [
    "## User-based neighborhood-based CF\n",
    "\n",
    "Idea podejścia **user-based** jest bardzo prosta - znajdźmy użytkowników podobnych do nas, którzy oceniali przedmioty, których my jeszcze nie widzieliśmy i zasugerujmy to, co potencjalnie najbardziej będzie się nam podobać. Realizuje podejście: \"użytkownicy podobni do ciebie oglądali także...\".\n",
    "\n",
    "Algorytm user-based collaborative filtering działa następująco:\n",
    "1. Dla każdego użytkownika znajdź k najbliższych sąsiadów.\n",
    "2. Predykcja dla przedmiotu to średnia ocena sąsiadów (którzy ocenili dany przedmiot) dla tego przedmiotu.\n",
    "3. Zarekomenduj te przedmioty, które mają najwyższą przewidywaną ocenę.\n",
    "\n",
    "Co ważne, przy obliczaniu najbliższych użytkowników bierzemy tylko te przedmioty, które obaj ocenili. Przykładowo, jeżeli użytkownik $u_1$ ocenił przedmioty $[1, 2, 3]$, a użytkownik $u_2$ ocenił przedmioty $[2, 3, 4]$, to na potrzeby obliczania ich podobieństwa bierzemy pod uwagę tylko $[2, 3]$. Przy obliczaniu predykcji dla $i$-tego przedmiotu także bierzemy pod uwagę tylko tych najbliższych sąsiadów, którzy wystawili mu ocenę.\n",
    "\n",
    "Predykcja dla użytkownika $u$ i przedmiotu $i$ to:\n",
    "\n",
    "$$\\large\n",
    "\\hat{r}_{ui} = \\frac{\\sum_{v \\in N_i^k(u)} \\text{sim}(u, v) * r_{vi}}{\\sum_{v \\in N_i^k(u)} \\text{sim}(u, v)},\n",
    "$$\n",
    "gdzie:\n",
    "- $N_i^k(u)$ - $k$ najbliższych sąsiadów dla użytkownika $u$, którzy ocenili przedmiot $i$,\n",
    "- $r_{vi}$ - ocena przedmiotu $i$ przez użytkownika $v$,\n",
    "- $\\text{sim}(u, v)$ - podobieństwo użytkowników $u$ i $v$ według metryki $\\text{sim}$.\n",
    "\n",
    "Co ważne, tutaj metryka jest podobieństwem, tzn. większa wartość = bardziej podobni użytkownicy. Typowo używa się **korelacji Pearsona (Pearson correlation)**, która przyjmuje wartości z zakresu $[-1; 1]$. Dzięki temu wiemy, którzy użytkownicy są bardzo podobni (blisko 1), którzy mają wręcz przeciwny gust do naszego (blisko -1), a którzy są w ogóle inni od nas (blisko 0). Niektóre implementacje (np. Surprise) biorą pod uwagę tylko sąsiadów o nieujemnej korelacji, a inne wykorzystują tę informację z ujemną wagą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "azz9xD0tZuT0",
    "outputId": "84556361-0dc5-46fb-b9ca-6885cd6869aa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0107\n",
      "MAE:  0.8016\n",
      "MAP@k (k=10): 74.08%\n",
      "FCP@k (k=10): 61.41%\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "knn_basic = KNNBasic(sim_options={\"name\": \"pearson\"})\n",
    "knn_basic.fit(train_set)\n",
    "pred_knn_basic = knn_basic.test(test_set)\n",
    "rec_knn_basic = get_recommendations(pred_knn_basic)\n",
    "\n",
    "print_metrics(pred_knn_basic, rec_knn_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMqXOHDVZuT0"
   },
   "source": [
    "Wynik nie jest może idealny, ale nie przeprowadziliśmy jeszcze żadnego tuningu hiperparametrów.\n",
    "\n",
    "Najważniejszym hiperparametrem jest **liczba sąsiadów `k`**. Trzeba wziąć pod uwagę, że nie wszystkie przedmioty będą się pokrywać między użytkownikami, więc typowo bierze się ich dość dużo. Jeżeli dana implementacja uwzględnia tylko nieujemne korelacje, to jeszcze więcej sąsiadów może odpaść, więc trzeba wziąć większą wartość. Jest to więc de facto maksymalna liczba sąsiadów do uwzględnienia. Im większa wartość, tym mocniejsza regularyzacja, bo uśredniamy więcej użytkowników. Przede wszystkim należy jednak wziąć pod uwagę wielkość naszego zbioru, szczególnie liczbę użytkowników oraz gęstość.\n",
    "\n",
    "Drugim hiperparametrem jest **minimalna liczba sąsiadów `min_k`**. Jeżeli spośród `k` najbliższych sąsiadów mniej niż `min_k` oceniło dany przedmiot, to mamy zimny start. Zwykle wykorzystuje się wtedy algorytm globalny, np. przewidując globalną średnią. Jak widać, system rekomendacyjny składa się w środku z bardzo wielu systemów rekomendacyjnych :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "lYovGRDxZuT0",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 6 (1 punkt)\n",
    "\n",
    "Przeprowadź tuning hiperparametrów, używając 10-krotnej walidacji skrośnej i optymalizując MAE. Jako że nasz zbiór jest dość mały, to sprawdzimy zakres:\n",
    "```\n",
    "param_grid = {\n",
    "    \"k\": list(range(10, 51, 10)),\n",
    "    \"min_k\": list(range(1, 4)),\n",
    "    \"sim_options\": {\"name\": [\"pearson\"]},\n",
    "    \"random_state\": [0],\n",
    "    \"verbose\": [False]\n",
    "}\n",
    "```\n",
    "\n",
    "Ponieważ interesują nas przede wszystkim same rekomendacje, optymalizuj metrykę FCP. Wypisz znalezione najlepsze hiperparametry oraz metryki na zbiorze testowym dla najlepszego modelu.\n",
    "\n",
    "Wskazówki:\n",
    "- użyj `GridSearchCV` z biblioteki Surprise,\n",
    "- argument `refit` ma domyślną wartość `False` - inaczej niż w Scikit-learn'ie,\n",
    "- wykorzystaj argument `n_jobs`,\n",
    "- niestety `random_state` trzeba przekazać jako hiperparametr, API Surprise jest tutaj niezbyt dobrze zrobione ([Github issue](https://github.com/NicolasHug/Surprise/issues/212)),\n",
    "- analogicznie do powyższego trzeba przekazać (dość dziwnie) `sim_options`,\n",
    "- analogicznie do powyższego działa przekazywanie `verbose` (żeby uniknąć zalewu tekstu).\n",
    "\n",
    "Skomentuj wyniki i zmiany w poszczególnych metrykach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0Btsgt-VZuT1",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "# your_code\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"k\": list(range(10, 51, 10)),\n",
    "    \"min_k\": list(range(1, 4)),\n",
    "    \"sim_options\": {\"name\": [\"pearson\"]},\n",
    "    \"random_state\": [0],\n",
    "    \"verbose\": [False]\n",
    "}\n",
    "\n",
    "knn_basic_gs = GridSearchCV(\n",
    "    KNNBasic,\n",
    "    param_grid,\n",
    "    measures=[\"mae\", \"fcp\"],\n",
    "    n_jobs=-1,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "knn_basic_gs.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_rcJN4k78bM",
    "outputId": "fe611f4b-b183-40ca-ac2a-31c89c4b14ec",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znalezione najlepsze hiperparametry dla optymalizowania FCP:\n",
      "{'k': 50, 'min_k': 1, 'sim_options': {'name': 'pearson', 'user_based': True}, 'random_state': 0, 'verbose': False}\n",
      "\n",
      "Najlepsza wartość metryki FCP: 0.68547697261354 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wartości metryk dla najlepszego modelu:\n",
      "RMSE: 1.0101\n",
      "MAE:  0.8014\n",
      "MAP@k (k=10): 74.14%\n",
      "FCP@k (k=10): 61.40%\n"
     ]
    }
   ],
   "source": [
    "# nowo dodana komórka\n",
    "fcp_best_params = knn_basic_gs.best_params[\"fcp\"]\n",
    "\n",
    "print(\"Znalezione najlepsze hiperparametry dla optymalizowania FCP:\")\n",
    "print(fcp_best_params)\n",
    "print(\"\\nNajlepsza wartość metryki FCP:\", knn_basic_gs.best_score[\"fcp\"], \"\\n\")\n",
    "\n",
    "knn_basic_tuned = KNNBasic(\n",
    "    k=fcp_best_params[\"k\"],\n",
    "    min_k=fcp_best_params[\"min_k\"],\n",
    "    sim_options=fcp_best_params[\"sim_options\"],\n",
    "    random_state=fcp_best_params[\"random_state\"],\n",
    "    verbose=fcp_best_params[\"verbose\"]\n",
    ")\n",
    "\n",
    "knn_basic_tuned.fit(train_set)\n",
    "\n",
    "pred_knn_basic_tuned = knn_basic_tuned.test(test_set)\n",
    "rec_knn_basic_tuned = get_recommendations(pred_knn_basic_tuned)\n",
    "\n",
    "print(\"\\nWartości metryk dla najlepszego modelu:\")\n",
    "print_metrics(pred_knn_basic_tuned, rec_knn_basic_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5YGfA4RuZuT1",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "assert 1 <= rmse(pred_knn_basic_tuned, verbose=False) <= 1.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "dynMmgtoZuT1",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "// skomentuj tutaj\n",
    "\n",
    "Po tuningu hiperparametrów pod kątem optymalizacji metryki FCP, udało się osiągnąć jej bardzo dobrą wartość (szczególnie w porównaniu do poprzednich modeli).\n",
    "\n",
    "Jeżeli chodzi o wartości metryk na najlepszym modelu, znacznych różnic nie ma. W porównaniu do modelu przed tuningiem, _RMSE_ i _MAE_ są nieco niższe. W przypadku metryki **MAP@k** jej wartość jest nieco wyższa, ale **FCP@k** jest praktycznie identyczna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "UZG2McFIZuT1",
    "tags": []
   },
   "source": [
    "Ten algorytm nie bierze jednak psychologicznych różnic między użytkownikami. Niektórzy użytkownicy będą średnio zawyżać oceny, bo film to dla nich luźna rozrywka, a poważni koneserzy mogą dawać filmom średnio dość niskie oceny. Taka tendencja to **user bias**, ale na szczęście można go policzyć - to po prostu średnia ocena wystawiana przez użytkownika, a więc średnia z każdego wiersza w macierzy ocen.\n",
    "\n",
    "Jeżeli od każdego wiersza odejmiemy jego średnią, to dostaniemy **ratings deviations**, czyli nie mamy już w macierzy samych ocen, tylko jak bardzo ocena danego przedmiotu przez użytkownika różni się od jego średniej predykcji. Taka operacja to **centrowanie (centering)**. Na takich wartościach można też zwyczajnie liczyć najbliższych sąsiadów, a korelacja Pearsona dalej działa dla takich danych. Żeby dokonać predykcji, przewidujemy odchylenie dla przedmiotu, a następnie dodajemy je dla średniej danego użytkownika.\n",
    "\n",
    "Mamy zatem:\n",
    "\n",
    "$$\\large\n",
    "\\hat{r}_{ui} = \\mu_i + \\frac{\\sum_{v \\in N_i^k(u)} \\text{sim}(u, v) * (r_{vi} - \\mu_v)}{\\sum_{v \\in N_i^k(u)} \\text{sim}(u, v)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "1LZbXmfxZuT1",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 7 (0.5 punktu)\n",
    "\n",
    "Analogicznie do poprzedniego zadania wytrenuj, zoptymalizuj i sprawdź na zbiorze treningowym user-based CF z centrowaniem (`KNNWithMeans`). Wypisz także optymalny zestaw hiperparametrów dla obu algorytmów.\n",
    "\n",
    "Skomentuj uzyskane hiperparametry i wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KWIJPjagZuT1",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "# your_code\n",
    "from surprise.prediction_algorithms.knns import KNNWithMeans\n",
    "\n",
    "param_grid = {\n",
    "    \"k\": list(range(10, 51, 10)),\n",
    "    \"min_k\": list(range(1, 4)),\n",
    "    \"sim_options\": {\"name\": [\"pearson\"]},\n",
    "    \"random_state\": [0],\n",
    "    \"verbose\": [False]\n",
    "}\n",
    "\n",
    "knn_centered_gs = GridSearchCV(\n",
    "    KNNWithMeans,\n",
    "    param_grid,\n",
    "    measures=[\"mae\", \"fcp\"],\n",
    "    n_jobs=-1,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "knn_centered_gs.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGmUJV0PJnQt",
    "outputId": "77142ce6-bb26-4ec4-aab1-41fbc7c1d27f",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znalezione najlepsze hiperparametry dla optymalizowania FCP:\n",
      "{'k': 50, 'min_k': 1, 'sim_options': {'name': 'pearson', 'user_based': True}, 'random_state': 0, 'verbose': False}\n",
      "\n",
      "Najlepsza wartość metryki FCP: 0.6831153350568712 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wartości metryk dla najlepszego modelu:\n",
      "RMSE: 0.9447\n",
      "MAE:  0.7374\n",
      "MAP@k (k=10): 73.83%\n",
      "FCP@k (k=10): 61.26%\n"
     ]
    }
   ],
   "source": [
    "# nowo dodana komórka\n",
    "fcp_best_params = knn_centered_gs.best_params[\"fcp\"]\n",
    "\n",
    "print(\"Znalezione najlepsze hiperparametry dla optymalizowania FCP:\")\n",
    "print(fcp_best_params)\n",
    "print(\"\\nNajlepsza wartość metryki FCP:\", knn_centered_gs.best_score[\"fcp\"], \"\\n\")\n",
    "\n",
    "knn_centered_tuned = KNNWithMeans(\n",
    "    k=fcp_best_params[\"k\"],\n",
    "    min_k=fcp_best_params[\"min_k\"],\n",
    "    sim_options=fcp_best_params[\"sim_options\"],\n",
    "    random_state=fcp_best_params[\"random_state\"],\n",
    "    verbose=fcp_best_params[\"verbose\"]\n",
    ")\n",
    "\n",
    "knn_centered_tuned.fit(train_set)\n",
    "\n",
    "pred_knn_centered_tuned = knn_centered_tuned.test(test_set)\n",
    "rec_knn_centered_tuned = get_recommendations(pred_knn_centered_tuned)\n",
    "\n",
    "print(\"\\nWartości metryk dla najlepszego modelu:\")\n",
    "print_metrics(pred_knn_centered_tuned, rec_knn_centered_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BKpBTf18ZuT1",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "assert 0.92 <= rmse(pred_knn_centered_tuned, verbose=False) <= 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "foKYi2J5ZuT1",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "// skomentuj tutaj\n",
    "\n",
    "Dla badanej siatki parametrów optymalny zestaw hiperparametrów okazał się taki sam, jak w poprzednim przypadku. Badając wartości metryk najlepszego modelu, po wycentrowaniu wartości **MAP@k** i **FCP@k** są nieco niższe (również najlepsza wartość **FCP@k** jest niższa), ale o wiele lepiej wypadają metryki _RMSE_ i _MAE_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "B4DxAjcwZuT2",
    "tags": []
   },
   "source": [
    "## Item-based neighborhood-based CF\n",
    "\n",
    "Idea podejścia **item-based** jest bardzo podobna do user-based, ale znajdujemy podobne przedmioty, a nie użytkowników. Operujemy zatem na kolumnach macierzy ocen. Realizuje to podejście \"mogą cię jeszcze zainteresować przedmioty...\" oraz \"skoro oglądałeś X, to mogą spodobać ci się...\".\n",
    "\n",
    "Predykcja dla użytkownika $u$ i przedmiotu $i$ to:\n",
    "\n",
    "$$\\large\n",
    "\\hat{r}_{ui} = \\frac{\\sum_{j \\in N_u^k(i)} \\text{sim}(u, v) * r_{uj}}{\\sum_{j \\in N_u^k(i)} \\text{sim}(u, v)}\n",
    "$$\n",
    "\n",
    "Podobieństwo przedmiotów liczymy tutaj według kolumn macierzy, a metryką jest zwykle **podobieństwo cosinusowe (cosine similarity)**. Wykorzystuje się także centrowanie, eliminując **item bias** - przykładowo, \"Titanic\" będzie miał zwykle zawyżone oceny, bo każdy słyszał, że to znany i dobry film, więc podświadomie zawyżymy mu ocenę. Metrykę po centralizacji nazywa się czasem *adjusted cosine similarity*.\n",
    "\n",
    "Podejście item-based zazwyczaj daje większą dokładność niż user-based, tzn. niższe RMSE i MAE. Skutkuje to jednak niższym pokryciem czy nowością. Takie podejście potrafi być też bardziej czułe na zimny start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "TH9ZYz5PZuT2",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 8 (0.5 punktu)\n",
    "\n",
    "Zaimplementuj podejście item-based z metryką cosinusową w wariantach:\n",
    "- bez normalizacji,\n",
    "- z centrowaniem (_adjusted cosine_).\n",
    "\n",
    "Analogicznie do poprzedniego ćwiczenia zastosuj optymalizację hiperparametrów, podaj najlepszy zestaw oraz wypisz metryki na zbiorze testowym.\n",
    "\n",
    "Żeby zamienić algorytm user-based na item-based oraz zmienić metrykę, przyda ci się [ten tutorial](https://surprise.readthedocs.io/en/stable/getting_started.html#tune-algorithm-parameters-with-gridsearchcv).\n",
    "\n",
    "Skomentuj, jaką uzyskano różnicę względem user-based i które rozwiązanie Twoim zdaniem jest lepsze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "e7gf5QZpZuT2",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "# your_code\n",
    "param_grid = {\n",
    "    \"k\": list(range(10, 51, 10)),\n",
    "    \"min_k\": list(range(1, 4)),\n",
    "    \"sim_options\": {\n",
    "        \"name\": [\"cosine\"],\n",
    "        \"user_based\": [False],\n",
    "    },\n",
    "    \"random_state\": [0],\n",
    "    \"verbose\": [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cfdx87XJ0Ye-",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "# nowo dodana komórka\n",
    "knn_item_gs = GridSearchCV(\n",
    "    KNNBasic,\n",
    "    param_grid,\n",
    "    measures=[\"mae\", \"fcp\"],\n",
    "    n_jobs=-1,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "knn_item_gs.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "JajGqNL-0YiS",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "# nowo dodana komórka\n",
    "knn_item_centered_gs = GridSearchCV(\n",
    "    KNNWithMeans,\n",
    "    param_grid,\n",
    "    measures=[\"mae\", \"fcp\"],\n",
    "    n_jobs=-1,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "knn_item_centered_gs.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUmUH-c20Ylo",
    "outputId": "4b7df2f7-6956-433c-c2a1-ce3734da7a47",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znalezione najlepsze hiperparametry dla optymalizowania FCP:\n",
      "{'k': 50, 'min_k': 1, 'sim_options': {'name': 'cosine', 'user_based': False}, 'random_state': 0, 'verbose': False}\n",
      "\n",
      "Najlepsza wartość metryki FCP: 0.588669142807745 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wartości metryk dla najlepszego modelu:\n",
      "RMSE: 1.0198\n",
      "MAE:  0.8064\n",
      "MAP@k (k=10): 73.97%\n",
      "FCP@k (k=10): 55.65%\n"
     ]
    }
   ],
   "source": [
    "# nowo dodana komórka\n",
    "fcp_best_params = knn_item_gs.best_params[\"fcp\"]\n",
    "\n",
    "print(\"Znalezione najlepsze hiperparametry dla optymalizowania FCP:\")\n",
    "print(fcp_best_params)\n",
    "print(\"\\nNajlepsza wartość metryki FCP:\", knn_item_gs.best_score[\"fcp\"], \"\\n\")\n",
    "\n",
    "knn_item_tuned = KNNBasic(\n",
    "    k=fcp_best_params[\"k\"],\n",
    "    min_k=fcp_best_params[\"min_k\"],\n",
    "    sim_options=fcp_best_params[\"sim_options\"],\n",
    "    random_state=fcp_best_params[\"random_state\"],\n",
    "    verbose=fcp_best_params[\"verbose\"]\n",
    ")\n",
    "\n",
    "knn_item_tuned.fit(train_set)\n",
    "\n",
    "pred_knn_item_tuned = knn_item_tuned.test(test_set)\n",
    "rec_knn_item_tuned = get_recommendations(pred_knn_item_tuned)\n",
    "\n",
    "print(\"\\nWartości metryk dla najlepszego modelu:\")\n",
    "print_metrics(pred_knn_item_tuned, rec_knn_item_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3mgLWJG0YpR",
    "outputId": "04dcf9fd-a499-4904-b27c-7d02dacf4e45",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znalezione najlepsze hiperparametry dla optymalizowania FCP:\n",
      "{'k': 50, 'min_k': 2, 'sim_options': {'name': 'cosine', 'user_based': False}, 'random_state': 0, 'verbose': False}\n",
      "\n",
      "Najlepsza wartość metryki FCP: 0.6797020791602397 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wartości metryk dla najlepszego modelu:\n",
      "RMSE: 0.9363\n",
      "MAE:  0.7340\n",
      "MAP@k (k=10): 74.24%\n",
      "FCP@k (k=10): 60.91%\n"
     ]
    }
   ],
   "source": [
    "# nowo dodana komórka\n",
    "fcp_best_params = knn_item_centered_gs.best_params[\"fcp\"]\n",
    "\n",
    "print(\"Znalezione najlepsze hiperparametry dla optymalizowania FCP:\")\n",
    "print(fcp_best_params)\n",
    "print(\"\\nNajlepsza wartość metryki FCP:\", knn_item_centered_gs.best_score[\"fcp\"], \"\\n\")\n",
    "\n",
    "knn_item_centered_tuned = KNNWithMeans(\n",
    "    k=fcp_best_params[\"k\"],\n",
    "    min_k=fcp_best_params[\"min_k\"],\n",
    "    sim_options=fcp_best_params[\"sim_options\"],\n",
    "    random_state=fcp_best_params[\"random_state\"],\n",
    "    verbose=fcp_best_params[\"verbose\"]\n",
    ")\n",
    "\n",
    "knn_item_centered_tuned.fit(train_set)\n",
    "\n",
    "pred_knn_item_centered_tuned = knn_item_centered_tuned.test(test_set)\n",
    "rec_knn_item_centered_tuned = get_recommendations(pred_knn_item_centered_tuned)\n",
    "\n",
    "print(\"\\nWartości metryk dla najlepszego modelu:\")\n",
    "print_metrics(pred_knn_item_centered_tuned, rec_knn_item_centered_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xWxbkR9YZuT2",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "assert 1 <= rmse(pred_knn_item_tuned, verbose=False) <= 1.03\n",
    "assert 0.92 <= rmse(pred_knn_item_centered_tuned, verbose=False) <= 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "Odf6kY8qZuT2",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "// skomentuj tutaj\n",
    "\n",
    "W przypadku wariantu bez normalizacji jest znaczna różnica względem podejścia _user-based_, ale **niekorzystna** - wartości metryk **MAP@k** i **FCP@k** są niższe, szczególnie ta druga.\n",
    "\n",
    "Dla wariantu z centrowaniem podejście _item-based_ radzi sobie już o wiele lepiej, chociaż w porównaniu do odpowiedniego modelu _user-based_ różnice nie są bardzo duże - wartości metryk są podobne, nieco lepsze są _RMSE_ i _MAE_.\n",
    "\n",
    "Podsumowując, według mnie w tym przypadku lepsze jest rozwiązanie **user-based**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "zgnVDNWzZuT2",
    "tags": []
   },
   "source": [
    "## Metody oparte o sąsiedztwo - podsumowanie\n",
    "\n",
    "Podsumowanie:\n",
    "1. Możemy wyróżnić dwa sposoby liczenia sąsiadów: user-based (inni użytkownicy, wiersze macierzy) oraz item-based (inne przedmioty, kolumny macierzy).\n",
    "2. Podejście user-based wykorzystuje zwykle korelację Pearsona, a item-based - podobieństwo cosinusowe.\n",
    "3. Użytkownicy oraz przedmioty mają naturalny bias (_user bias_, _item bias_), który można wyeliminować, stosując normalizację: centrowanie lub standaryzację.\n",
    "\n",
    "Zalety:\n",
    "1. Prostota.\n",
    "2. Interpretowalność, szczególnie dla item-based.\n",
    "3. Stosunkowo niewielka czułość na dobór hiperparametrów.\n",
    "4. Można idealnie uwspółbieżnić trening oraz predykcję (problem _embarassingly parallel_).\n",
    "\n",
    "Wady:\n",
    "1. Dość trudna implementacja, trzeba wybierać wspólne przedmioty.\n",
    "2. Trening jest niezbyt skalowalny dla bardzo dużych danych.\n",
    "3. Czułe na zimny start.\n",
    "4. Bardzo niewiele implementacji wspiera dodawanie nowych użytkowników/przedmiotów - trzeba przetrenowywać regularnie cały model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "BpDe6RdzZuT2",
    "tags": []
   },
   "source": [
    "# Metody oparte o rozkład macierzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSIk1YLHZuT2"
   },
   "source": [
    "Podejście najbliższych sąsiadów definiuje \"sąsiedztwo\" bardzo explicite - wymaga, by użytkownicy ocenili dokładnie te same filmy, aby w ogóle sprawdzać, czy są podobni. Nie wykorzystuje to niejawnych podobieństw między przedmiotami i filmami. Przykładowo, jeżeli jeden lubi filmy \"Szeregowiec Ryan\", \"Dunkierka\" i \"Wróg u bram\", a drugi lubi filmy \"Czas apokalipsy\" i \"Jak rozpętałem drugą wojnę światową\", to są do siebie bardzo podobni, a jednak podejście user-based nawet nie będzie w stanie tego sprawdzić. Item-based mogłoby tu nieco pomóc, ale tam mogą się zdarzyć analogiczne sytuacje.\n",
    "\n",
    "Podejście oparte o rozkład macierzy, spopularyzowane w ramach konkursu **Netflix Prize 2007** przez Simona Funka ([wywiad](https://www.kdd.org/exploration_files/simon-funk-explorations.pdf), [jego blog](https://sifter.org/simon/journal/20061211.html)) rozwiązuje właśnie ten problem. Stanowi kamień milowy w systemach rekomendacyjnych, gdyż daje bardzo dobre wyniki, doskonale uwspółbieżnia się i rozprasza na wiele maszyn, a do tego jest naprawdę proste. Szczegółowy i bardzo przystępny opis tego podejścia można znaleźć w artykule [\"Matrix factorization techniques for recommender systems\" Y. Koren, R. Bell, C. Volinsky](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf).\n",
    "\n",
    "Ideą jest, aby dokonać **rozkładu macierzy (matrix decomposition)** na macierzy ocen $R$, przybliżając ją jako iloczyn dwóch macierzy: $W$ (user matrix) i $U$ (item matrix), które reprezentują użytkowników i przedmioty po dekompozycji:\n",
    "\n",
    "$$\\large\n",
    "\\hat{R} = WU^T\n",
    "$$\n",
    "\n",
    "![matrix_decomposition.png](attachment:matrix_decomposition.png)\n",
    "\n",
    "Załóżmy, że mamy $N$ użytkowników i $M$ przedmiotów. Kształty macierzy to zatem:\n",
    "\n",
    "$$\\large\n",
    "\\hat{R}_{N \\times M} = W_{N \\times K} U_{K \\times M}^T\n",
    "$$\n",
    "\n",
    "Pojawił nam się nowy wymiar $K$ - każdy użytkownik to teraz wektor z macierzy $W$ o długości $K$, a każdy przedmiot to wektor z macierzy $U$ o długości $K$. Jest to **ukryta wymiarowość (latent dimensionality)**, stanowiąca hiperparametr, analogiczny np. do rozmiaru warstw sieci neuronowej. Nie są to interpretowalne cechy, ale można zauważyć przy dobrym modelu, że odwzorowują pewne ogólne tematy w danych. Przykładowo, dla filmów (przedmiotów) mogą oznaczać, jak dużo jest poszczególnych tematów w filmie, np. \"romans\", \"komedia\", \"akcja\". Dla użytkowników mogą oznaczać, w jak dużym stopniu użytkownik interesuje się danym tematem. Typowe wartości $K$ to około kilkadziesiąt-kilkaset. Ze względu na wykorzystanie latent dimensionality takie modele nazywa się też **latent factor models**.\n",
    "\n",
    "Predykcji w takim modelu dokonuje się przez iloczyn skalarny wektora użytkownika (wiersz $W$) z wektorem przedmiotu (kolumna $U$):\n",
    "\n",
    "$$\\large\n",
    "r_{ui} = w_u^Tu_i\n",
    "$$\n",
    "\n",
    "Dzięki takiemu sformułowaniu, jeśli zainteresowanie użytkownika tematem $k$ będzie duże, a film będzie zawierał dużo tematu $k$, to ich mnożenie da dużą wartość, a zatem dużą predykcję.\n",
    "\n",
    "Algorytm ten nazywa się czasem niepoprawnie SVD, bo takiej nazwy użył Simon Funk do opisu swojego algorytmu (jego wersja ma trochę ulepszeń; będziemy ją nazywać _FunkSVD_). Co ważne, nie wykorzystujemy tutaj algorytmu SVD, bo nie potrzebujemy całego jego aparatu matematycznego. Zamiast tego ten algorytm to po prostu **matrix factorization (MF)**, tudzież **Probabilistic Matrix Factorization (PMF)** ([oryginalny artykuł PMF](https://proceedings.neurips.cc/paper/2007/file/d7322ed717dedf1eb4e6e52a37ea7bcd-Paper.pdf) dowodzi, że to sformułowanie jest poprawne probabilistycznie). Trenuje się go także bez SVD, zamiast tego wykorzystując spadek wzdłuż gradientu lub algorytm **Alternating Least Squares (ALS)**. Ciężko powiedzieć, które podejście jest lepsze, patrz np. [ta dyskusja](https://stats.stackexchange.com/questions/201279/comparison-of-sgd-and-als-in-collaborative-filtering), [ten paper](http://cs229.stanford.edu/proj2014/Christopher%20Aberger,%20Recommender.pdf). Oba podejścia bardzo dobrze opisuje [ten artykuł](https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/), który rozwija też bardziej formalnie, czemu ekstrakcja \"tematów\" działa (spoiler: MF dokonuje implicite klasteryzacji).\n",
    "\n",
    "Niezależnie od podejścia, minimalizuje się funkcję kosztu, czyli różnicę między naszym przybliżeniem $\\hat{R} = WU^T$, a prawdziwą macierzą $R$. Zwykle wykorzystuje się tutaj błąd średniokwadratowy, w zapisie macierzowym $||\\hat{R} - R||_2^2$. Zapisując to ręcznie:\n",
    "\n",
    "$$\\large\n",
    "L = \\sum_{u, i \\in \\Omega} \\left( r_{ui} - \\hat{r}_{ui} \\right)^2,\n",
    "$$\n",
    "gdzie $\\Omega$ to zbiór wszystkich wypełnionych komórek w macierzy ocen.\n",
    "\n",
    "Jako że mamy dwie macierze do nauczenia, $W$ oraz $U$, to mamy pochodną po wektorach $w$ oraz po wektorach $u$. Po przekształceniach dostajemy:\n",
    "\n",
    "$$\\large\n",
    "w_i = \\left( \\sum_{j \\in \\Psi_i} u_ju_j^T \\right)^{-1} \\sum_{j \\in \\Psi_i} r_{ij}u_j,\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "u_j = \\left( \\sum_{i \\in \\Omega_j} w_iw_i^T \\right)^{-1} \\sum_{i \\in \\Omega_j} r_{ij}w_i,\n",
    "$$\n",
    "gdzie:\n",
    "- $\\Psi_i$ oznacza zbiór przedmiotów, które ocenił użytkownik $i$,\n",
    "- $\\Omega_j$ oznacza zbiór użytkowników, którzy ocenili przedmiot $j$.\n",
    "\n",
    "Można zauważyć, że w obu przypadkach jest to zwyczajny nadokreślony (*overdetermined*) układ równań postaci $x=A^{-1}b$. Taki problem rozwiązuje się metodą najmniejszych kwadratów (*ordinary least squares*), stąd część nazwy metody. Oczywiście do rozwiązania problemu OLS można użyć SVD.\n",
    "\n",
    "Przybliżymy teraz krótko metodę ALS, bo SGD znamy już z sieci neuronowych. Można zauważyć w powyższych wzorach, że dla $W$ pochodna zależy od wartości w $U$, a dla $U$ od wartości w $W$ - wydaje się, że sytuacja patowa. Rozwiązaniem jest po prostu przyjąć losowy punkt wyjścia, a potem raz rozwiązywać $W$ za pomocą $U$, a raz na odwrót.\n",
    "\n",
    "Pełny algorytm ALS:\n",
    "1. Zainicjalizuj losowo macierze $W$ i $U$ niewielkimi wartościami z rozkładu normalnego.\n",
    "2. Powtarzaj przez $T$ kroków:\n",
    "  1. Zaktualizuj $U$ według wzoru, rozwiązując układ równań; $W$ jest stałe.\n",
    "  2. Zaktualizuj $W$ według wzoru, rozwiązując układ równań; $U$ jest stałe.\n",
    "\n",
    "Co ważne, zbieżność i ALS, i spadku wzdłuż gradientu jest gwarantowana, ale do minimum lokalnego. Zwykle nie stanowi to jednak problemu, a w razie czego zawsze można wytrenować wiele modeli na różnych `random_state` i wybrać najlepszy. Liczba epok treningowych stanowi dość prosty hiperparametr - im więcej, tym dokładniejsi po prostu będziemy, więc możemy bardziej overfitować (analogicznie do sieci neuronowych). Zazwyczaj w przypadku ALS wystarcza niewielka liczba, kilka-kilkanaście."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jo2rd3IuZuT3"
   },
   "source": [
    "Surprise implementuje wersję z SGD. Wersję z ALS implementuje np. _Apache Spark_. Wersję z SGD można też łatwo zaimplementować w dowolnym frameworku do sieci neuronowych, np. PyTorch czy TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pT8Dm4EbZuT3",
    "outputId": "d4623b29-7e49-4033-9c18-f79183f69185"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9671\n",
      "MAE:  0.7596\n",
      "MAP@k (k=10): 74.12%\n",
      "FCP@k (k=10): 60.76%\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# regular MF - no user/item bias, no regularization\n",
    "mf = SVD(biased=False, reg_all=0, random_state=0)\n",
    "mf.fit(train_set)\n",
    "\n",
    "pred_mf = mf.test(test_set)\n",
    "rec_mf = get_recommendations(pred_mf)\n",
    "\n",
    "print_metrics(pred_mf, rec_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8Gk98igZuT3"
   },
   "source": [
    "Dostaliśmy całkiem dobry wynik bez żadnego tuningu, a czeka nas jeszcze trochę ulepszeń, bo powyższy algorytm to jeszcze nie słynny FunkSVD.\n",
    "\n",
    "Skoro user bias i item bias pomagały w metodach opartych o sąsiedztwo, to dodajmy je też tutaj - czemu nie? Najpierw możemy odjąć od wszystkiego globalną średnią $\\mu$, żeby wycentrować całą macierz. Potem odejmujemy od każdego wiersza user bias $b_u$, a na koniec od każdej kolumny item bias $b_i$. Predykcja to zatem:\n",
    "\n",
    "$$\\large\n",
    "\\hat{r}_{ui} = \\mu + b_u + b_i + w_u^Tu_i\n",
    "$$\n",
    "\n",
    "Drugie ulepszenie to dodanie regularyzacji do naszej funkcji kosztu. W końcu nie możemy się zbyt bardzo dostosować do zbioru treningowego, bo nasz algorytm ma generalizować się dla przyszłych rekomendacji. Co ważne, mamy tutaj aż 4 możliwe źródła przeuczenia:\n",
    "- $b_u$ - zbytnie dostosowanie do dotychczasowych odchyleń użytkowników,\n",
    "- $b_i$ - analogicznie, ale dla przedmiotów,\n",
    "- $w_u$ - jest to wektor wag, więc duże wagi oznaczają overfitting, jak np. w regresji liniowej,\n",
    "- $u_i$ - analogicznie, ale dla drugiej macierzy.\n",
    "\n",
    "Możnaby użyć 4 osobnych współczynników regularyzacji, ale optymalizacja takiej siatki hiperparametrów jest raczej mało wykonalna. Można więc użyć jednego hiperparametru $\\lambda$ na moc regularyzacji L2, włączając do niego wszystkie parametry. Daje to funkcję kosztu:\n",
    "\n",
    "$$\\large\n",
    "L = \\sum_{u, i \\in \\Omega} \\left( r_{ui} - \\hat{r}_{ui} \\right)^2 + \\lambda \\left( ||W||_2^2 + ||U||_2^2 + ||b_u||_2^2 + ||b_i||_2^2 \\right)\n",
    "$$\n",
    "\n",
    "Pomijając dalsze wyprowadzenie, nic nie zmienia to w gruncie rzeczy w algorytmie ALS, dalej możemy użyć zwykłego OLS, zmienią się tylko trochę wartości w macierzach. Niewiele zmienia się też, gdy używamy spadku wzdłuż gradientu - dodajemy tylko regularyzację do funkcji kosztu.\n",
    "\n",
    "Powyższe sformułowanie to już pełny algorytm FunkSVD. Zobaczmy, jak sobie poradzi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yd8rsMlVZuT3",
    "outputId": "e855af57-63c8-4ac6-a031-7a253bc915bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9308\n",
      "MAE:  0.7323\n",
      "MAP@k (k=10): 74.05%\n",
      "FCP@k (k=10): 61.08%\n"
     ]
    }
   ],
   "source": [
    "funk_svd = SVD(biased=True, random_state=0)\n",
    "funk_svd.fit(train_set)\n",
    "\n",
    "pred_funk_svd = funk_svd.test(test_set)\n",
    "rec_funk_svd = get_recommendations(pred_funk_svd)\n",
    "\n",
    "print_metrics(pred_funk_svd, rec_funk_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVtyxdNeZuT3",
    "tags": []
   },
   "source": [
    "Wygląda to na bardzo dobry wynik, a nie dokonaliśmy jeszcze żadnego tuningu hiperparametrów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "DYTEZnMTZuT3",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie 9 (1 punkt)\n",
    "\n",
    "Zaimplementuj tuning hiperparametrów dla algorytmu FunkSVD, sprawdzając siatkę hiperparametrów:\n",
    "```\n",
    "param_grid = {\n",
    "    \"n_factors\": list(range(50, 151, 10)),\n",
    "    \"lr_all\": [0.001, 0.003, 0.005, 0.007, 0.01],\n",
    "    \"reg_all\": [0.01, 0.02, 0.03]\n",
    "}\n",
    "```\n",
    "\n",
    "Pamiętaj, aby przekazać stałe `random_state`! Przyda się też `n_jobs`. Jeżeli na twoim sprzęcie będzie się to liczyć o wiele za długo, to możesz zmniejszyć zakres `n_factors` do 80-121.\n",
    "\n",
    "Skomentuj wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "d2cpxhIlZuT4",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "# your_code\n",
    "param_grid = {\n",
    "    \"n_factors\": list(range(80, 121, 10)),\n",
    "    \"lr_all\": [0.001, 0.003, 0.005, 0.007, 0.01],\n",
    "    \"reg_all\": [0.01, 0.02, 0.03],\n",
    "    \"random_state\": [0],\n",
    "    \"verbose\": [False]\n",
    "}\n",
    "\n",
    "funk_svd_gs = GridSearchCV(\n",
    "    SVD,\n",
    "    param_grid,\n",
    "    measures=[\"mae\", \"fcp\"],\n",
    "    n_jobs=-1,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "funk_svd_gs.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vmbu8fQdl1mR",
    "outputId": "1171fe85-b0be-47e8-b976-a8beb1e6f02c",
    "tags": [
     "ex"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znalezione najlepsze hiperparametry dla optymalizowania FCP:\n",
      "{'n_factors': 80, 'lr_all': 0.007, 'reg_all': 0.03, 'random_state': 0, 'verbose': False}\n",
      "\n",
      "Najlepsza wartość metryki FCP: 0.6802153012290019 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-441673c5b200>:13: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  .agg({\"actual\": (lambda x: list(x))})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wartości metryk dla najlepszego modelu:\n",
      "RMSE: 0.9280\n",
      "MAE:  0.7281\n",
      "MAP@k (k=10): 73.88%\n",
      "FCP@k (k=10): 60.76%\n"
     ]
    }
   ],
   "source": [
    "# nowo dodana komórka\n",
    "fcp_best_params = funk_svd_gs.best_params[\"fcp\"]\n",
    "\n",
    "print(\"Znalezione najlepsze hiperparametry dla optymalizowania FCP:\")\n",
    "print(fcp_best_params)\n",
    "print(\"\\nNajlepsza wartość metryki FCP:\", funk_svd_gs.best_score[\"fcp\"], \"\\n\")\n",
    "\n",
    "funk_svd_tuned = SVD(\n",
    "    n_factors=fcp_best_params[\"n_factors\"],\n",
    "    lr_all=fcp_best_params[\"lr_all\"],\n",
    "    reg_all=fcp_best_params[\"reg_all\"],\n",
    "    random_state=fcp_best_params[\"random_state\"],\n",
    "    verbose=fcp_best_params[\"verbose\"]\n",
    ")\n",
    "\n",
    "funk_svd_tuned.fit(train_set)\n",
    "\n",
    "pred_funk_svd_tuned = funk_svd_tuned.test(test_set)\n",
    "rec_funk_svd_tuned = get_recommendations(pred_funk_svd_tuned)\n",
    "\n",
    "print(\"\\nWartości metryk dla najlepszego modelu:\")\n",
    "print_metrics(pred_funk_svd_tuned, rec_funk_svd_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "AhAAndzWZuT4",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "assert 0.9 <= rmse(pred_funk_svd_tuned, verbose=False) <= 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "L6tFb4gzZuT4",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "// skomentuj tutaj\n",
    "\n",
    "W przypadku tuningu dla FunkSVD zdecydowanie poprawiły się wartości metryk _RMSE_ i _MAE_ - spośród wszystkich badanych modeli podczas tego laboratorium osiągają one najniższą wartość.\n",
    "\n",
    "Pozostałe metryki wypadają nienajgorzej, ale nie wyróżniają się na tle pozostałych modeli, nawet przyjmują nieco gorszą wartość.\n",
    "\n",
    "Można uznać ten model za najlepszy spośród testowanych, ale jest to okupione dłuższym czasem przeszukiwania siatki hiperparametrów - nawet dla okrojonego zestawu wartości parametru `n_factors`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "SelNPp4aZuT4",
    "tags": []
   },
   "source": [
    "## Metody oparte o rozkład macierzy - podsumowanie\n",
    "\n",
    "Podsumowanie:\n",
    "1. Macierz ocen można zdekomponować do iloczynu macierzy użytkowników $W$ oraz macierzy przedmiotów $U$.\n",
    "2. W tym podejściu wprowadzamy dodatkowy ukryty wymiar (latent dimension) wielkości $K$, który reprezentuje tematy ukryte w naszych danych.\n",
    "3. Do obliczania macierzy minimalizuje się błąd przybliżenia macierzy ocen przez nasze macierze $W$ i $U$. Służy do tego albo spadek wzdłuż gradientu, albo, bardziej typowo, algorytm Alternating Least Squares (ALS).\n",
    "\n",
    "Zalety:\n",
    "1. Bardzo dobre wyniki.\n",
    "2. Szybkość i skalowalność.\n",
    "3. Możliwość przyspieszenia obliczeń z pomocą GPU.\n",
    "4. Działa dość dobrze w przypadku zimnego startu.\n",
    "\n",
    "Wady:\n",
    "1. Dość dużo hiperparametrów, przynajmniej w przypadku użycia spadku wzdłuż gradientu.\n",
    "2. Brak optymalnego wyniku, trzebaby wypróbować różne losowe punkty startowe.\n",
    "3. Niska interpretowalność.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "Mp8adbp4ZuT4",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "## Zadanie dodatkowe (3 punkty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKlxFo_gZuT4",
    "tags": [
     "ex"
    ]
   },
   "source": [
    "Uruchom na zbiorze MovieLens-1M (albo innym podobnego rozmiaru) algorytm LightGCN ([artykuł](https://arxiv.org/pdf/2002.02126.pdf)), implementujący podejście grafowe do rekomendacji z użyciem biblioteki LibRecommender ([tutorial](https://github.com/massquantity/LibRecommender/blob/master/examples/pure_ranking_example.py)), która pod spodem używa PyTorch Geometric ([tutorial dla odważnych](https://colab.research.google.com/drive/1VfP6JlWbX_AJnx88yN1tM3BYE6XAADiy?usp=sharing)). Poniżej opis, jak to działa, ale znajomość teorii nie jest potrzebna do wykonania tego zadania :) Możesz użyć domyślnych hiperparametrów architektury sieci z tutoriala, ale zaimplementuj tuning przynajmniej liczby epok (LibRecommender nie ma early stoppingu). Jeżeli zbiór 1M jest za duży dla twojego sprzętu, możesz pracować na 100k. Jeżeli użyjesz MovieLens-1M, dla porównania zaimplementuj także wybrane 1-2 algorytmy z tego laboratorium na tym zbiorze (możesz po prostu skopiować kod z komórek notebooka powyżej).\n",
    "\n",
    "W tym podejściu reprezentujemy problem jako graf, a nie jako macierz. Mamy graf dwudzielny użytkowników i przedmiotów, gdzie ocena reprezentowana jest jako krawędź między wierzchołkiem użytkownika, a wierzchołkiem przedmiotu, opisana oceną. Rekomendacja polega na zadaniu **przewidywania krawędzi (edge prediction)**, czyli zasugerowanie dodania nowej krawędzi między użytkownikiem, a przedmiotem.\n",
    "\n",
    "Sieć LightGCN implementuje podejście collaborative filtering na grafie. Jest to **grafowa sieć neuronowa (Graph Neural Network, GNN)**, osiągająca obecnie jedne z najlepszych wyników wśród systemów CF. Każdy wierzchołek ma tutaj wektor o pewnej założonej z góry długości $N$, tzw. _embedding_. Tworzy się go następująco:\n",
    "- robimy one-hot encoding dla użytkowników i przedmiotów, kodując ich `user_id` i `item_id`,\n",
    "- mnożymy użytkowników przez macierz, robiąc kombinację liniową i rzutując na niższy wymiar,\n",
    "- to samo, co wyżej, tylko dla przedmiotów.\n",
    "\n",
    "Macierze embeddujące dla użytkowników i przedmiotów są parametrami, których uczymy się wraz z treningiem sieci neuronowej. Inicjalizuje się je losowo.\n",
    "\n",
    "Sieć LightGCN składa się z kilku warstw **konwolucji grafowej (graph convolution)**, gdzie każda warstwa agreguje informacje z sąsiednich wierzchołków. Dla każdego wierzchołka robimy po prostu sumę ważoną wektorów sąsiadów ($e_u$ - embedding użytkownika $u$, $e_i$ - embedding przedmiotu $i$):\n",
    "\n",
    "$$\\large\n",
    "e_u^{(k+1)} = \\sum_{i \\in N(u)} \\frac{1}{\\sqrt{N(u)}\\sqrt{N(i)}} e_i^{(k)}\n",
    "$$\n",
    "Sąsiadów ważymy ich stopniem, aby wziąć pod uwagę popularność poszczególnych przedmiotów i aktywność użytkowników (mają duży stopień). Taka wymiana informacji między wierzchołkami propaguje informację w grafie, aktualizując embeddingi.\n",
    "\n",
    "Typowo takich warstw jest kilka, np. 3-4. Później agreguje się informacje ze wszystkich warstw, w odróżnieniu od sieci CNN dla obrazów, gdzie zwykle bierze się wyjście tylko z ostatniej warstwy. Dla każdego użytkownika (i przedmiotu) bierzemy jego embedding z każdej warstwy i uśredniamy je. Daje to bogatą reprezentację wierzchołka i agreguje informacje zarówno z bliskiego sąsiedztwa (głębokie warstwy), jak i z ogółu społeczności w grafie (wysokie warstwy).\n",
    "\n",
    "Predykcja to po prostu iloczyn skalarny embeddingu użytkownika i przedmiotu: $r_{ij} = e_j^T e_i$. Sieć taką uczy się zwykle funkcją kosztu **Bayesian Personalized Ranking (BPR)**, używaną powszechnie w sieciach neuronowych do systemów rekomendacyjnych. Oczywiście uwzględnia się tu wszystkie typowe elementy sieci neuronowych: learning rate, weight decay etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4wv0mvOZuT4",
    "tags": [
     "ex"
    ]
   },
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
